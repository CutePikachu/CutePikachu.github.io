<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Operating Systems - Tina blog</title><meta description="The more you know about operating system, the better you can cooperate with it."><meta property="og:type" content="blog"><meta property="og:title" content="Operating Systems"><meta property="og:url" content="https://cutepikachu.github.io/2020/08/11/OperatingSystems/"><meta property="og:site_name" content="Tina blog"><meta property="og:description" content="The more you know about operating system, the better you can cooperate with it."><meta property="og:locale" content="en_US"><meta property="og:image" content="https://i.loli.net/2020/08/11/PSC79mFMgHtBJka.png"><meta property="og:image" content="https://i.loli.net/2020/08/11/PGARtc4jS3ZaTw2.png"><meta property="og:image" content="https://i.loli.net/2020/08/11/2JnaABHRtuLzsFe.png"><meta property="og:image" content="https://i.loli.net/2020/08/11/ktRXLZrOBs3SqfG.png"><meta property="og:image" content="https://i.loli.net/2020/08/11/Le91OJ7ucdvDCSH.png"><meta property="og:image" content="https://i.loli.net/2020/08/11/EKDX9qVAuTWLnOz.png"><meta property="og:image" content="https://i.loli.net/2020/08/11/MlD64Kr7HdQcU8k.png"><meta property="og:image" content="https://i.loli.net/2020/08/11/isXUFBeqLTcGmp3.png"><meta property="og:image" content="https://i.loli.net/2020/08/11/knB6cJT9ZeqrCI3.png"><meta property="og:image" content="https://i.loli.net/2020/08/11/JeLm8X3VGC2n7pq.png"><meta property="og:image" content="https://i.loli.net/2020/08/11/DZzw3m6SFgTqpl8.png"><meta property="og:image" content="https://i.loli.net/2020/08/11/Ex5KcXF1yrqpf8S.png"><meta property="og:image" content="https://i.loli.net/2020/08/11/U1ex7Gy8n5E9wVX.png"><meta property="og:image" content="https://i.loli.net/2020/08/11/bDZvzo62eSswWGC.png"><meta property="og:image" content="https://i.loli.net/2020/08/11/LQtb9AFBuiUDM4v.png"><meta property="og:image" content="https://i.loli.net/2020/08/11/8mCWRXsqgQeTMV9.png"><meta property="og:image" content="https://i.loli.net/2020/08/11/4FdkPJrNBqoZp6E.png"><meta property="og:image" content="https://i.loli.net/2020/08/11/21zuAcOstYon6U4.png"><meta property="og:image" content="https://i.loli.net/2020/08/11/CcVnqFvNhegibot.jpg"><meta property="og:image" content="https://i.loli.net/2020/08/11/3Zor8IVpRyS9CB4.jpg"><meta property="og:image" content="https://i.loli.net/2020/08/11/NfeLorh5vn1XDRt.png"><meta property="og:image" content="https://i.loli.net/2020/08/12/DKAoVLU2cIPZmpY.png"><meta property="og:image" content="https://i.loli.net/2020/08/11/MdNZAm7jUfcIxyt.png"><meta property="og:image" content="https://i.loli.net/2020/08/12/91kJERBLhyXTl8g.png"><meta property="og:image" content="https://camo.githubusercontent.com/2eaefc6a0f092437ad16b57402907a70e8c74cfe/68747470733a2f2f692e6c6f6c692e6e65742f323032302f30382f31322f796a3575633452736b4c745837426c2e706e67"><meta property="og:image" content="https://camo.githubusercontent.com/570a1431dfae252b0637499522201e11d013842f/68747470733a2f2f692e6c6f6c692e6e65742f323032302f30382f31322f485233674a556e35364170737237422e706e67"><meta property="og:image" content="https://camo.githubusercontent.com/0355867ac61976685db709062c07d784418005db/68747470733a2f2f692e6c6f6c692e6e65742f323032302f30382f31322f6871377874596f553647586a6579482e706e67"><meta property="og:image" content="https://camo.githubusercontent.com/d83dae3a02b89d1e414c55152619c9a102b811c5/68747470733a2f2f692e6c6f6c692e6e65742f323032302f30382f31322f48504177326a556637596c6e6238742e706e67"><meta property="og:image" content="https://camo.githubusercontent.com/0655d295daf917fc49926538f29597a86fd48203/68747470733a2f2f692e6c6f6c692e6e65742f323032302f30382f31322f63526b3671746d79335751355559722e706e67"><meta property="og:image" content="https://camo.githubusercontent.com/0655d295daf917fc49926538f29597a86fd48203/68747470733a2f2f692e6c6f6c692e6e65742f323032302f30382f31322f63526b3671746d79335751355559722e706e67"><meta property="article:published_time" content="2020-08-11T06:00:00.000Z"><meta property="article:modified_time" content="2020-08-13T11:16:54.905Z"><meta property="article:author" content="Tina"><meta property="article:tag" content="OS"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://i.loli.net/2020/08/11/PSC79mFMgHtBJka.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://cutepikachu.github.io/2020/08/11/OperatingSystems/"},"headline":"Tina blog","image":["https://i.loli.net/2020/08/11/PSC79mFMgHtBJka.png","https://i.loli.net/2020/08/11/PGARtc4jS3ZaTw2.png","https://i.loli.net/2020/08/11/2JnaABHRtuLzsFe.png","https://i.loli.net/2020/08/11/ktRXLZrOBs3SqfG.png","https://i.loli.net/2020/08/11/Le91OJ7ucdvDCSH.png","https://i.loli.net/2020/08/11/EKDX9qVAuTWLnOz.png","https://i.loli.net/2020/08/11/MlD64Kr7HdQcU8k.png","https://i.loli.net/2020/08/11/isXUFBeqLTcGmp3.png","https://i.loli.net/2020/08/11/knB6cJT9ZeqrCI3.png","https://i.loli.net/2020/08/11/JeLm8X3VGC2n7pq.png","https://i.loli.net/2020/08/11/DZzw3m6SFgTqpl8.png","https://i.loli.net/2020/08/11/Ex5KcXF1yrqpf8S.png","https://i.loli.net/2020/08/11/U1ex7Gy8n5E9wVX.png","https://i.loli.net/2020/08/11/bDZvzo62eSswWGC.png","https://i.loli.net/2020/08/11/LQtb9AFBuiUDM4v.png","https://i.loli.net/2020/08/11/8mCWRXsqgQeTMV9.png","https://i.loli.net/2020/08/11/4FdkPJrNBqoZp6E.png","https://i.loli.net/2020/08/11/21zuAcOstYon6U4.png","https://i.loli.net/2020/08/11/CcVnqFvNhegibot.jpg","https://i.loli.net/2020/08/11/3Zor8IVpRyS9CB4.jpg","https://i.loli.net/2020/08/11/NfeLorh5vn1XDRt.png","https://i.loli.net/2020/08/12/DKAoVLU2cIPZmpY.png","https://i.loli.net/2020/08/11/MdNZAm7jUfcIxyt.png","https://i.loli.net/2020/08/12/91kJERBLhyXTl8g.png"],"datePublished":"2020-08-11T06:00:00.000Z","dateModified":"2020-08-13T11:16:54.905Z","author":{"@type":"Person","name":"Tina"},"description":"The more you know about operating system, the better you can cooperate with it."}</script><link rel="canonical" href="https://cutepikachu.github.io/2020/08/11/OperatingSystems/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="Tina blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/projects">Projects</a></div><div class="navbar-end"><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-08-11T06:00:00.000Z" title="2020-08-11T06:00:00.000Z">2020-08-11</time><span class="level-item"><a class="link-muted" href="/categories/notes/">notes</a></span><span class="level-item">2 hours read (About 14771 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">Operating Systems</h1><div class="content"><blockquote>
<p>The more you know about operating system, the better you can cooperate with it.</p>
</blockquote>
<a id="more"></a>

<h1 id="Operating-System-Overview"><a href="#Operating-System-Overview" class="headerlink" title="Operating System Overview"></a>Operating System Overview</h1><h2 id="Role"><a href="#Role" class="headerlink" title="Role"></a>Role</h2><h3 id="Role-1"><a href="#Role-1" class="headerlink" title="Role 1"></a>Role 1</h3><blockquote>
<p>The Operating System is an Abstract Machine</p>
</blockquote>
<ul>
<li>Extends the basic hardware with added functionality</li>
<li>Provides high-level abstractions<ul>
<li>More programmer friendly</li>
<li>Common core for all applications</li>
</ul>
</li>
<li>It hides the details of the hardware<ul>
<li>Makes application code portable</li>
</ul>
</li>
</ul>
<h3 id="Role-2"><a href="#Role-2" class="headerlink" title="Role 2"></a>Role 2</h3><blockquote>
<p>The Operating System is a Resource Manager</p>
</blockquote>
<ul>
<li>Responsible for allocating resources to users and processes</li>
<li>Must ensure<ul>
<li>No Starvation</li>
<li>Progress</li>
<li>Allocation is according to some desired policy<ul>
<li>First-come, first-served; Fair share; Weighted fair share; limits (quotas), etc…</li>
</ul>
</li>
<li>Overall, that the system is efficiently used</li>
</ul>
</li>
</ul>
<h2 id="Structural-Implementation-View"><a href="#Structural-Implementation-View" class="headerlink" title="Structural (Implementation) View"></a>Structural (Implementation) View</h2><blockquote>
<p>the Operating System is the software Privileged mode. </p>
</blockquote>
<p><img src="https://i.loli.net/2020/08/11/PSC79mFMgHtBJka.png" alt=""> </p>
<h3 id="Operating-System-Kernel"><a href="#Operating-System-Kernel" class="headerlink" title="Operating System Kernel"></a>Operating System Kernel</h3><ul>
<li>Portion of the operating system that is running in privileged mode</li>
<li>Usually resident (stays) in main memory</li>
<li>Contains fundamental functionality<ul>
<li>Whatever is required to implement other services</li>
<li>Whatever is required to provide security</li>
</ul>
</li>
<li>Contains most-frequently used functions</li>
<li>Also called the nucleus or supervisor</li>
</ul>
<h3 id="The-Operating-System-is-Privileged"><a href="#The-Operating-System-is-Privileged" class="headerlink" title="The Operating System is Privileged"></a>The Operating System is Privileged</h3><blockquote>
<p>Applications should not be able to interfere or bypass the operating system</p>
</blockquote>
<p>OS can enforce the “extended machine”</p>
<p>OS can enforce its resource allocation policies</p>
<p>Prevent applications from interfering with each other</p>
<h2 id="The-Structure-of-a-Computer-System"><a href="#The-Structure-of-a-Computer-System" class="headerlink" title="The Structure of a Computer System"></a>The Structure of a Computer System</h2><p><img src="https://i.loli.net/2020/08/11/PGARtc4jS3ZaTw2.png" alt=""></p>
<ul>
<li>Applications interact with themselves and via function calls to library procedures</li>
<li>OS and application interacts via <strong>System calls</strong></li>
</ul>
<h3 id="A-Note-on-System-Libraries"><a href="#A-Note-on-System-Libraries" class="headerlink" title="A Note on System Libraries"></a>A Note on System Libraries</h3><blockquote>
<p>System libraries are just that, libraries of support functions (procedures, subroutines)</p>
</blockquote>
<p>Only a subset of library functions are actually system calls, and system call functions are in the library for convenience</p>
<h2 id="Privilege-less-OS"><a href="#Privilege-less-OS" class="headerlink" title="Privilege-less OS"></a>Privilege-less OS</h2><blockquote>
<p>Can implement OS functionality, but cannot enforce it.</p>
</blockquote>
<p>Some Embedded OSs have no privileged component</p>
<ul>
<li>All software runs together</li>
<li>No isolation</li>
<li>One fault potentially brings down entire system</li>
</ul>
<h2 id="Operating-System-Software"><a href="#Operating-System-Software" class="headerlink" title="Operating System Software"></a>Operating System Software</h2><ul>
<li><p>Fundamentally, OS functions the same way as ordinary computer software. </p>
<ul>
<li>It is machine code that is executed (same machine instructions as application). </li>
<li>It has more privileges (extra instructions and access).</li>
</ul>
</li>
<li><p>Operating system relinquishes control of the processor to execute other programs, it reestablishes control after </p>
<ul>
<li>System calls </li>
<li>and Interrupts (especially timer interrupts).</li>
</ul>
</li>
</ul>
<h3 id="Operating-System-Internal-Structure"><a href="#Operating-System-Internal-Structure" class="headerlink" title="Operating System Internal Structure"></a>Operating System Internal Structure</h3><blockquote>
<p>The Monolithic Operating System Structure, Also called the “spaghetti nest” approach(Everything is tangled up with everything else. )</p>
</blockquote>
<h1 id="Processes-and-Threads"><a href="#Processes-and-Threads" class="headerlink" title="Processes and Threads"></a>Processes and Threads</h1><h2 id="Major-Requirements-of-an-Operating-System"><a href="#Major-Requirements-of-an-Operating-System" class="headerlink" title="Major Requirements of an Operating System"></a>Major Requirements of an Operating System</h2><ul>
<li>Interleave the execution of several processes to maximize processor utilization while providing reasonable response time</li>
<li>Allocate resources to processess</li>
<li>Support interprocess communication and user creation of processes</li>
</ul>
<h2 id="Processes-and-Threads-1"><a href="#Processes-and-Threads-1" class="headerlink" title="Processes and Threads"></a>Processes and Threads</h2><p><strong>Processes</strong></p>
<ul>
<li>Also called a task or job</li>
<li>Execution of an individual program</li>
<li>“Owner” of resources allocated for program execution<ul>
<li>trace the usage of processes, clean up memory after finishing execution</li>
</ul>
</li>
<li>Encompasses one or more threads</li>
</ul>
<p><strong>Threads</strong></p>
<blockquote>
<p>The sequence of execution through an application</p>
</blockquote>
<ul>
<li>Unit of execution</li>
<li>Can be traced<ul>
<li>list the sequence of instructions that execute</li>
</ul>
</li>
<li>Belongs to a process<ul>
<li>Process provide environment, and all thread running in the process share the environment</li>
<li>Executes within it</li>
</ul>
</li>
</ul>
<h2 id="Process"><a href="#Process" class="headerlink" title="Process"></a>Process</h2><h3 id="The-Process-Model"><a href="#The-Process-Model" class="headerlink" title="The Process Model"></a>The Process Model</h3><p>Single process machine<br><img src="https://i.loli.net/2020/08/11/2JnaABHRtuLzsFe.png" alt="the process model"></p>
<ul>
<li>Multiprogramming of four programs</li>
<li>Conceptual model of 4 independent, sequential processes(with a single thread each)</li>
<li>Only one program active at any instant</li>
</ul>
<p><img src="https://i.loli.net/2020/08/11/ktRXLZrOBs3SqfG.png" alt="threads and processes"></p>
<blockquote>
<p>the box represents a process, and the line represents the thread and the dotted lines represent what the OS can do</p>
</blockquote>
<h3 id="Process-and-thread-models-of-selected-OSes"><a href="#Process-and-thread-models-of-selected-OSes" class="headerlink" title="Process and thread models of selected OSes"></a>Process and thread models of selected OSes</h3><ul>
<li>Single process, single thread<ul>
<li>MSDOS</li>
</ul>
</li>
<li>Signle process, multiple threads<ul>
<li>OS/161 as distributed</li>
</ul>
</li>
<li>Multiple processes, single thread<ul>
<li>Traditional UNIX</li>
</ul>
</li>
<li>Multiple processes, multiple threads<ul>
<li>Modern Unix(Linux, Solaris), Windows</li>
</ul>
</li>
</ul>
<h3 id="Process-Creation"><a href="#Process-Creation" class="headerlink" title="Process Creation"></a>Process Creation</h3><p><strong>Principal events that cause process creation</strong></p>
<ul>
<li>System initialization<ul>
<li>Foreground processes(interactive programs)</li>
<li>Background processes<ul>
<li>Email server, web server, print server, etc.</li>
<li>Called a daemon(unix) or service(Windows)</li>
</ul>
</li>
</ul>
</li>
<li>Execution of a process creation system call by running a process<ul>
<li>New login shell for an incoming ssh connection</li>
</ul>
</li>
<li>User request to create a new process</li>
<li>Initiation of a bach job</li>
</ul>
<blockquote>
<p>Note: Technically, all these cases use the same system machanism to create new processes</p>
</blockquote>
<h3 id="Process-Termination"><a href="#Process-Termination" class="headerlink" title="Process Termination"></a>Process Termination</h3><p><strong>Conditions which terminate processes</strong></p>
<ul>
<li>Normal exit(voluntary)</li>
<li>Error exit(voluntary)</li>
<li>Fatal error(involuntary)<ul>
<li>e.g. segmentation fault</li>
</ul>
</li>
<li>Killed by another process(involuntary)</li>
</ul>
<h3 id="Implementation-of-Processes"><a href="#Implementation-of-Processes" class="headerlink" title="Implementation of Processes"></a>Implementation of Processes</h3><ul>
<li>A processes’ information is stored in a process control block(PCB)</li>
<li>The PCBs form a process table<ul>
<li>Reality can be complex(hashing, chaining, allocation bitmaps,…)</li>
<li>Size can be dynamic</li>
</ul>
</li>
</ul>
<p><strong>Example fields of a process table entry</strong></p>
<table>
<thead>
<tr>
<th>Process Management</th>
<th>Memory management</th>
<th>File management</th>
</tr>
</thead>
<tbody><tr>
<td>Registers</td>
<td>Pointer to text segment</td>
<td>Root directory</td>
</tr>
<tr>
<td>Program counter</td>
<td>Pointer to data segment</td>
<td>working directory</td>
</tr>
<tr>
<td>Program status word</td>
<td>Pointer to stack segement</td>
<td>File descriptors</td>
</tr>
<tr>
<td>Stack pointer</td>
<td></td>
<td>User ID</td>
</tr>
<tr>
<td>Process state</td>
<td></td>
<td>Group ID</td>
</tr>
<tr>
<td>Priority</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Scheduling parameters</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Process ID</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Parent process</td>
<td></td>
<td></td>
</tr>
<tr>
<td>process group</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Signals</td>
<td></td>
<td></td>
</tr>
<tr>
<td>time when process started</td>
<td></td>
<td></td>
</tr>
<tr>
<td>CPU time used</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Children’s CPU time</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Time of next alarm</td>
<td></td>
<td></td>
</tr>
</tbody></table>
<h3 id="Process-Thread-States"><a href="#Process-Thread-States" class="headerlink" title="Process/Thread States"></a>Process/Thread States</h3><p>Three states process model(the minial model the OSes implement)<img src="https://i.loli.net/2020/08/11/Le91OJ7ucdvDCSH.png" alt="states"></p>
<blockquote>
<p>In the image the numbers prepresent:</p>
<ol>
<li>Process blocks for input</li>
<li>Scheduler picks another process</li>
<li>Scheculer picks this process</li>
<li>Input becomes available</li>
</ol>
</blockquote>
<ul>
<li>Possible process/thread states<ul>
<li>running</li>
<li>blocked</li>
<li>ready</li>
</ul>
</li>
</ul>
<blockquote>
<p>Generally, if no IO, processes almost all sitting in running and ready</p>
</blockquote>
<ul>
<li>Transitions between states shown</li>
</ul>
<p><strong>some Transition Causing Events</strong></p>
<ul>
<li>Running -&gt; Ready<ul>
<li>Voluntary Yield()</li>
<li>End of timeslice</li>
</ul>
</li>
<li>Running -&gt; Blocked<ul>
<li>Waiting fot input<ul>
<li>File, network,</li>
</ul>
</li>
<li>Waiting for a timer(alarm signal)</li>
<li>Waiting for a resource to become available</li>
</ul>
</li>
</ul>
<h3 id="Scheduler"><a href="#Scheduler" class="headerlink" title="Scheduler"></a>Scheduler</h3><blockquote>
<p>responsible for want to run next</p>
</blockquote>
<ul>
<li>Sometimes alse called the dispatcher<ul>
<li>The literature is alse a little inconsistent on with terminology</li>
</ul>
</li>
<li>Has to choose a Ready process to run<ul>
<li>It is inefficent to search through all processes</li>
</ul>
</li>
</ul>
<p><strong>The Ready Queue</strong><br><img src="https://i.loli.net/2020/08/11/EKDX9qVAuTWLnOz.png" alt="ready queue"></p>
<h4 id="What-about-blocked-processes"><a href="#What-about-blocked-processes" class="headerlink" title="What about blocked processes"></a>What about blocked processes</h4><blockquote>
<p>When an unblocking event occurs, we also wish to avoid scanning all processes to select one to make <em>Ready</em></p>
</blockquote>
<p>using two queues(One option)<br><img src="https://i.loli.net/2020/08/11/MlD64Kr7HdQcU8k.png" alt="blocked queue"></p>
<p>another option(using a queue for every event)<br><img src="https://i.loli.net/2020/08/11/isXUFBeqLTcGmp3.png" alt="blocked queues"></p>
<h3 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h3><ul>
<li>Minimally consist of three segments <ul>
<li>Text <ul>
<li>contains the code (instructions) </li>
</ul>
</li>
<li>Data  <ul>
<li>Global variables  </li>
</ul>
</li>
<li>Stack <ul>
<li>Activation records of procedure/function/method </li>
<li>Local variables </li>
</ul>
</li>
</ul>
</li>
<li>User-mode<ul>
<li>Processes (programs) scheduled by the kernel</li>
<li>Isolated from each other</li>
<li>No concurrency issues between each other</li>
</ul>
</li>
<li>System-calls transition into and return from the kernel</li>
<li>Kernel-mode<ul>
<li>Nearly all activities still associated with a process</li>
<li>Kernel memory shared between all processes</li>
<li>Concurrency issues exist between processes concurrently executing in a system call</li>
</ul>
</li>
</ul>
<h2 id="Thread"><a href="#Thread" class="headerlink" title="Thread"></a>Thread</h2><h3 id="The-Thread-Model"><a href="#The-Thread-Model" class="headerlink" title="The Thread Model"></a>The Thread Model</h3><p><img src="https://i.loli.net/2020/08/11/knB6cJT9ZeqrCI3.png" alt="thread model"></p>
<blockquote>
<p>(a) Three processes each with one thread<br>(b) One process with three thread</p>
</blockquote>
<p><strong>Separating execution from the environment</strong></p>
<table>
<thead>
<tr>
<th>Per process items</th>
<th>Per thread items</th>
</tr>
</thead>
<tbody><tr>
<td>Address space</td>
<td>Program counter</td>
</tr>
<tr>
<td>Global variables</td>
<td>Registers</td>
</tr>
<tr>
<td>Open files</td>
<td>Stack</td>
</tr>
<tr>
<td>Child processess</td>
<td>State</td>
</tr>
<tr>
<td>Pending alarms</td>
<td></td>
</tr>
<tr>
<td>Signals and signal handlers</td>
<td></td>
</tr>
<tr>
<td>Accounting information</td>
<td></td>
</tr>
</tbody></table>
<ul>
<li><p>Items shared by all threads in a process</p>
</li>
<li><p>Item private to each thread</p>
</li>
<li><p>The Thread Model</p>
<ul>
<li>State implicitly stored on the stack</li>
<li><img src="https://i.loli.net/2020/08/11/JeLm8X3VGC2n7pq.png" alt="the state model"></li>
<li>Local variables are per thread<ul>
<li>Allocated on the stack</li>
<li>Don’t have concurrency issues</li>
</ul>
</li>
<li>Global variables are shared between all threads<ul>
<li>Allocated in the data section</li>
<li>Concurrency control is an issue</li>
</ul>
</li>
<li>Dynamically allocated memory(malloc) can be glocal or local<ul>
<li>Program defined(the pointer can be global or local)</li>
<li>If the pointer is global variable(has concurrency issue) while locals don’t</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Thread-Usage"><a href="#Thread-Usage" class="headerlink" title="Thread Usage"></a>Thread Usage</h3><p><strong>Example</strong></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// dispatcher thread</span></span><br><span class="line">While(TRUE) &#123;</span><br><span class="line">	get_next_request(&amp;buf);</span><br><span class="line">	handoff_work(&amp;buf);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// worker thread - can overlap disk I/O with the execution of other threads</span></span><br><span class="line"><span class="keyword">while</span> (TRUE) &#123;</span><br><span class="line">	wait_for_work(&amp;buf);</span><br><span class="line">	look_for_page_in_cache(&amp;buf, &amp;page);</span><br><span class="line">	<span class="keyword">if</span> (page_not_in_cache(&amp;page)</span><br><span class="line">		read_page_from_disk(&amp;buf, &amp;page);</span><br><span class="line">	return_page(&amp;page);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>Model</th>
<th>Characteristics</th>
</tr>
</thead>
<tbody><tr>
<td>Threads</td>
<td>Parallelism, blocking system calls</td>
</tr>
<tr>
<td>Sigle-threaded process</td>
<td>No parallelism, blocking system calls</td>
</tr>
<tr>
<td>Finite-state machine</td>
<td>Parallelism, nonblocking system calls, interrupts</td>
</tr>
</tbody></table>
<h3 id="Why-Threads"><a href="#Why-Threads" class="headerlink" title="Why Threads?"></a>Why Threads?</h3><ul>
<li>Simpler to program than a state machine</li>
<li>Less resources are associated with them a complete process<ul>
<li>Cheaper to create and destory</li>
<li>Shares resources(especially memory) between them</li>
</ul>
</li>
<li>Performace: Threads waiting for I/O can be overlapped with computing threads<ul>
<li>Note if all threads are compute bound, then there is no performance improvement(on a uniprocessor)</li>
</ul>
</li>
<li>Threads can take advantage of the parallelism available on machines with more than one CPU(multiprocessor)</li>
</ul>
<h3 id="User-level-Threads"><a href="#User-level-Threads" class="headerlink" title="User-level Threads"></a>User-level Threads</h3><ul>
<li>Implementation at user-level<ul>
<li>User-level Thread Control Block (TCB), ready queue, blocked queue, and dispatcher</li>
<li>Kernel has no knowledge of the threads (it only sees a single process) </li>
<li>If a thread blocks waiting for a resource held by another thread inside the same process, its state is saved and the dispatcher switches to another ready thread</li>
<li>Thread management (create, exit, yield, wait) are implemented in a runtime support library</li>
</ul>
</li>
<li>Pros<ul>
<li>Thread management and switching at user level is much faster than doing it in kernel level<ul>
<li>No need to trap (take syscall exception) into kernel and back to switch</li>
</ul>
</li>
<li>Dispatcher algorithm can be tuned to the application</li>
<li>Can be implemented on any OS (thread or non-thread aware)</li>
<li>Can easily support massive numbers of threads on a per-application basis<ul>
<li>Use normal application virtual memory</li>
<li>Kernel memory more constrained. Difficult to efficiently support wildly differing numbers of threads for different applications.</li>
</ul>
</li>
</ul>
</li>
<li>Cons<ul>
<li>Threads have to yield() manually (no timer interrupt delivery to userlevel)<ul>
<li>Co-operative multithreading<ul>
<li>A single poorly design/implemented thread can monopolise the available CPU time</li>
</ul>
</li>
<li>There are work-arounds (e.g. a timer signal per second to enable preemptive multithreading), they are course grain and a kludge.</li>
</ul>
</li>
<li>Does not take advantage of multiple CPUs (in reality, we still have a single threaded process as far as the kernel is concerned)</li>
<li>If a thread makes a blocking system call (or takes a page fault), the process (and all the internal threads) blocks<ul>
<li>Can’t overlap I/O with computation</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Kernel-level-threads"><a href="#Kernel-level-threads" class="headerlink" title="Kernel-level threads"></a>Kernel-level threads</h3><ul>
<li><p>Cons </p>
<ul>
<li>Thread creation and destruction, and blocking and unblocking threads requires kernel entry and exit. <ul>
<li>More expensive than user-level equivalent</li>
</ul>
</li>
</ul>
</li>
<li><p>Pros </p>
<ul>
<li>Preemptive multithreading </li>
<li>Parallelism <ul>
<li>Can overlap blocking I/O with computation </li>
<li>Can take advantage of a multiprocessor </li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Context-Switch"><a href="#Context-Switch" class="headerlink" title="Context Switch"></a>Context Switch</h2><blockquote>
<p>A context switch can refer to a switch between threads, involving saving and restoring of state associated with a thread; A switch between processes, involving the above, plus extra state associated with a process.</p>
</blockquote>
<h3 id="Context-Switch-Occurrence"><a href="#Context-Switch-Occurrence" class="headerlink" title="Context Switch Occurrence"></a>Context Switch Occurrence</h3><p>A switch between process/threads can happen any time the OS is invoked</p>
<ul>
<li>On a system call<ul>
<li>Mandatory if system call blocks or on exit()</li>
</ul>
</li>
<li>On an exception<ul>
<li>Mandatory if offender is killed</li>
</ul>
</li>
<li>On an interrupt<ul>
<li>Triggering a dispatch is the main purpose of the timer interrupt</li>
</ul>
</li>
</ul>
<p>A thread switch can happen between any two instructions</p>
<p>Note instructions do not equal program statements</p>
<h3 id="Context-Switch-1"><a href="#Context-Switch-1" class="headerlink" title="Context Switch"></a>Context Switch</h3><ul>
<li>Context switch must be transparent for processes/threads<ul>
<li>When dispatched again, process/thread should not notice that something else was running in the meantime (except for elapsed time)</li>
<li>OS must save all state that affects the thread</li>
</ul>
</li>
<li>This state is called the process/thread context</li>
<li>Switching between process/threads consequently results in a context switch.</li>
</ul>
<h1 id="Concurrency-and-Synchronisation"><a href="#Concurrency-and-Synchronisation" class="headerlink" title="Concurrency and Synchronisation"></a>Concurrency and Synchronisation</h1><p><strong>Concurrency Example</strong></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// count is a global variable shared between two threads</span></span><br><span class="line"><span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">increment</span> <span class="params">()</span> </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="keyword">int</span> t;</span><br><span class="line">	t = count;</span><br><span class="line">	t = t + <span class="number">1</span>;</span><br><span class="line">	count = t;</span><br><span class="line">&#123;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">decrement</span> <span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="keyword">int</span> t;</span><br><span class="line">	t = count;</span><br><span class="line">	t = t - <span class="number">1</span>;</span><br><span class="line">	count = t;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Have a race condition. Occurred when global variables shared by threads</p>
</blockquote>
<p><code>There is in-kernel concurrency even for single-threaded process</code><br>The OS has to deal with concurrency even if it is a single thread application.<br><img src="https://i.loli.net/2020/08/11/DZzw3m6SFgTqpl8.png" alt="image"></p>
<h2 id="Critical-Region"><a href="#Critical-Region" class="headerlink" title="Critical Region"></a>Critical Region</h2><ul>
<li>We can control access to the shared resource by controlling access to the code that accesses the resource</li>
</ul>
<blockquote>
<p>A critical region is a region of code where shared resources are accessed(e.g. Variables, memory, files, etc…)</p>
</blockquote>
<ul>
<li>Uncoordinated entry to the critical region results in a race condition<ul>
<li>=&gt; Incorrect behavior, deadlock, lost work,…</li>
</ul>
</li>
</ul>
<p><strong>Indentifying critical regions</strong></p>
<ul>
<li>Critical regions are regions of code that:<ul>
<li>Access a shared resource,</li>
<li>and correctness relied on the shared resource not being concurrently modified by another thread/process/entity.</li>
</ul>
</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// count is a global variable shared between two threads</span></span><br><span class="line"><span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">increment</span> <span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        <span class="keyword">int</span> t;</span><br><span class="line">        t = count; <span class="comment">// the start of critical region</span></span><br><span class="line">        t = t + <span class="number">1</span>;</span><br><span class="line">        count = t; <span class="comment">// end</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">decrement</span> <span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        <span class="keyword">int</span> t;</span><br><span class="line">        t = count; <span class="comment">// start</span></span><br><span class="line">        t = t - <span class="number">1</span>;</span><br><span class="line">        count = t; <span class="comment">// end</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>if we can make the critical regions never overlap, we won’t have concurrency problem.<br><img src="https://i.loli.net/2020/08/11/Ex5KcXF1yrqpf8S.png" alt="mutual exclusion using critical regions"></p>
<p><strong>Example critical regions</strong></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">node</span> &#123;</span></span><br><span class="line">	<span class="keyword">int</span> data;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">node</span> *<span class="title">next</span>;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">node</span> *<span class="title">head</span>;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">init</span><span class="params">(<span class="keyword">void</span>)</span> </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	head = <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">insert</span><span class="params">(struct *item)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	item-&gt;next = head;</span><br><span class="line">	head = item;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">struct node *<span class="title">remove</span><span class="params">(<span class="keyword">void</span>)</span> </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">node</span> *<span class="title">t</span>;</span></span><br><span class="line">	t = head;</span><br><span class="line">	<span class="keyword">if</span> (t != <span class="literal">NULL</span>) &#123;</span><br><span class="line">		head = head-&gt;next;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> t;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>Race example</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// thread 1</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">insert</span><span class="params">(struct *item)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        item-&gt;next = head; <span class="comment">// 1</span></span><br><span class="line">        head = item;       <span class="comment">// 2</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// thread 2</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">insert</span><span class="params">(struct *item)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        item-&gt;next = head; <span class="comment">// 3</span></span><br><span class="line">        head = item;       <span class="comment">// 4</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>one possible sequence: 1 -&gt; 3 -&gt; 2 -&gt; 4, then the item in thread 1 is lost(seg fault)<br>both1-2 and 3-4 are critical regions</p>
<h4 id="Critical-regions-solutions"><a href="#Critical-regions-solutions" class="headerlink" title="Critical regions solutions"></a>Critical regions solutions</h4><ul>
<li>We seek a solution to coordinate access to critical regions<ul>
<li>Also called critical sections</li>
</ul>
</li>
<li>Conditions required of any solution to the critical region problem<ul>
<li>Mutual Exclusion: No two processes simultaneously in critical region</li>
<li>No assumptions made about speeds or numbers of CPUs</li>
<li>Progress<ul>
<li>No process running outside its critical region may block another process</li>
</ul>
</li>
<li>Bounded<ul>
<li>No process waits forever to enter its critical region</li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>A solution?</p>
</blockquote>
<ul>
<li>A lock variable<ul>
<li>if lock == 1, somebody is in the critical section and we mush wait</li>
<li>if lock == 0, nobody is in the critical section and we are free to enter</li>
</ul>
</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// A problematic execution sequence</span></span><br><span class="line"><span class="keyword">while</span> (TRUE) &#123;</span><br><span class="line">	<span class="keyword">while</span> (lock == <span class="number">1</span>); <span class="comment">// 1</span></span><br><span class="line">	lock = <span class="number">1</span>;          <span class="comment">// 2</span></span><br><span class="line">	critical();        <span class="comment">// 3</span></span><br><span class="line">	lock = <span class="number">0</span>;          <span class="comment">// 4</span></span><br><span class="line">	non_critical();    <span class="comment">// 5</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> (TRUE) &#123;</span><br><span class="line">	<span class="keyword">while</span> (lock == <span class="number">1</span>); <span class="comment">// 6</span></span><br><span class="line">        lock = <span class="number">1</span>;          <span class="comment">// 7</span></span><br><span class="line">        critical();        <span class="comment">// 8</span></span><br><span class="line">        lock = <span class="number">0</span>;          <span class="comment">// 9</span></span><br><span class="line">        non_critical();    <span class="comment">// 10</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/* does not work because if it execute like</span></span><br><span class="line"><span class="comment">* 6 -&gt; 1 -&gt; 2 -&gt; 3</span></span><br><span class="line"><span class="comment">* both of them see the lock is not one and may all work in their critical section</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>In the example above, there is race contition between the observation that the lock variable is not one and setting the lock to prevent somebody else from entering.</p>
</blockquote>
<p><strong>Mutual Exclusion by Taking Turns</strong></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (TRUE) &#123;</span><br><span class="line">	<span class="keyword">while</span> (<span class="built_in">turn</span> != <span class="number">0</span>);</span><br><span class="line">	critcal_rigion();</span><br><span class="line">	<span class="built_in">turn</span> = <span class="number">1</span>;</span><br><span class="line">	noncritical_region();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">while</span> (TRUE) &#123;</span><br><span class="line">        <span class="keyword">while</span> (<span class="built_in">turn</span> != <span class="number">1</span>);</span><br><span class="line">        critcal_rigion();</span><br><span class="line">        <span class="built_in">turn</span> = <span class="number">0</span>;</span><br><span class="line">        noncritical_region();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>This example works because the update is only been updated by the thread having its turn.</p>
</blockquote>
<ul>
<li>Works due to strict alternation<ul>
<li>Each process takes turns</li>
</ul>
</li>
<li>Cons<ul>
<li>Busy waiting(loop)<ul>
<li>sol: not my turn, do sth else, come back to my turn</li>
</ul>
</li>
<li>Process must wait its turn even while the other process is doing something else.<ul>
<li>With many processes, must wait for everyone to have a turn<ul>
<li>Does not guarantee progress if a process no longer needs a turn</li>
</ul>
</li>
<li>Poor solution when processes require the critical section at differing rates</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>Mutual Exclusion by Disabling Interrupts</strong></p>
<blockquote>
<p>only used in very short critical sections, because it prespond other devices in the machine and make them less responsive</p>
</blockquote>
<ul>
<li>Before entering a critical region, disable interrupts</li>
<li>After leaving the critical region, enable interrupts</li>
<li>Pros<ul>
<li>simple</li>
</ul>
</li>
<li>Cons<ul>
<li>Only available in the kernel</li>
<li>Blocks everybody else, even with no contention<ul>
<li>slows interrupt response time</li>
</ul>
</li>
<li>Does not work on a multiprocessor</li>
</ul>
</li>
</ul>
<p><strong>Hardware Support for mutual exclusion</strong></p>
<ul>
<li>Test and set instruction<ul>
<li>can be used to implement lock variables correctly<ul>
<li>It loads the value of the lock</li>
<li>If lock == 0,<ul>
<li>set the lock to 1</li>
<li>return the result 0 – we acquire the lock</li>
</ul>
</li>
<li>If lock == 1<ul>
<li>return 1 – another thread/process has the lock</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Hardware guarantees that the instruction executes atomically(atomically: as an indivisible unit)</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">enter_region:</span><br><span class="line">	TSL REFISTER,LOCK | copy lock to register and set lock to 1</span><br><span class="line">	CMP REGISTER, #0  | was lock one?</span><br><span class="line">	JNE enter_region  | if it was non zero, lock was set, so loop</span><br><span class="line">	RET               | return to caller; critical region entered</span><br><span class="line"></span><br><span class="line">leave_region:</span><br><span class="line">	MOVE LOCK, #0     | store a 0 in lock</span><br><span class="line">	RET               | return to caller</span><br></pre></td></tr></table></figure>

<ul>
<li>Pros<ul>
<li>Simple(easy to show it’s correct)</li>
<li>Available at user-level<ul>
<li>To any number of processors</li>
<li>To implement any number of lock variables</li>
</ul>
</li>
</ul>
</li>
<li>Cons<ul>
<li>Busy waits(also termed a spin lock)<ul>
<li>consumes CPU</li>
<li>starvation is possible when a process leaves its critical section and more than one process is waiting</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>Tackling the Busy-Wait Problem</strong></p>
<ul>
<li>Sleep / Wake up<ul>
<li>The idea     <ul>
<li>When process is waiting for an event, it calls sleep to block, instead of busy waiting</li>
<li>The event happens, the event generator(another process) calls wakeup to unblock the sleeping process.</li>
<li>Walking a ready/running process has no effect</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="The-producer-Consumer-Problem"><a href="#The-producer-Consumer-Problem" class="headerlink" title="The producer-Consumer Problem"></a>The producer-Consumer Problem</h3><blockquote>
<p>Also called the bounded buffer problem<br>A producer produces data items and stores the items in a buffer<br>A consumer takes the items out of the buffer and consumes them.</p>
</blockquote>
<ul>
<li>two problems: Concurrency(because shared resource) and the producer should be blocked when the buffer is full and the consumer should be blocked when the buffer is empty.<ul>
<li>We must keep accurate count of items in the buffer</li>
<li>The consumer can call wakeup when it consumes the first entry of the full buffer</li>
<li>The Producer can call wakeup when it adds the first item to the buffer</li>
</ul>
</li>
</ul>
<h3 id="Semaphores"><a href="#Semaphores" class="headerlink" title="Semaphores"></a>Semaphores</h3><ul>
<li>Dijkstra introduced two primitives that are more powerful than simple sleep and wakeup alone.<ul>
<li>P(): proberen, from Dutch to test</li>
<li>V(): verhogen, from Dutch to increment</li>
<li>Also called wait &amp; signal, down &amp; up</li>
</ul>
</li>
</ul>
<blockquote>
<p>How do they work</p>
</blockquote>
<ul>
<li>If a resource is not available, the corresponding semaphore blocks any process waiting for the resource</li>
<li>Blocked processes are put into a process queue maintained by the semaphore(avoids busy waiting)</li>
<li>When a process releases a resource, it signals this by means of the semaphore</li>
<li>Signalling resumes a blocked process if there is any</li>
<li>Wait(P) and signal(V) operations cannot be interrupted</li>
<li>Complex coordination can be implemented by multiple semaphores</li>
</ul>
<p><strong>Semaphore implementation</strong></p>
<ul>
<li>Define a semaphore as a record</li>
</ul>
<blockquote>
<p>Each primitive is atomit(wait and signal), the OS would use the disabling of interrupts in the implementation of Semaphore inside the OS.</p>
</blockquote>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> sturct &#123;</span><br><span class="line">	<span class="keyword">int</span> count;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">process</span> *<span class="title">L</span>;</span></span><br><span class="line">&#125; semaphore;</span><br><span class="line"><span class="comment">// Semaphore operations now defined as</span></span><br><span class="line">wait(S):</span><br><span class="line">	S.count --;</span><br><span class="line">	<span class="keyword">if</span> (S.count &lt; <span class="number">0</span>) &#123;</span><br><span class="line">		add <span class="keyword">this</span> <span class="built_in">process</span> to S.L;</span><br><span class="line">		sleep;</span><br><span class="line">	&#125;</span><br><span class="line">signal(S):</span><br><span class="line">	S.count++;</span><br><span class="line">	<span class="keyword">if</span> (S.count &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">		<span class="built_in">remove</span> a <span class="built_in">process</span> P from S.L;</span><br><span class="line">		wakeup(P);</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>

<p><strong>Semaphore as a General Synchronization Tool</strong></p>
<ul>
<li>Execute B in Pj only after A executed in Pi</li>
<li>Use semaphore count initlialized to 0</li>
<li>Code:<br><img src="https://i.loli.net/2020/08/11/U1ex7Gy8n5E9wVX.png" alt="code"><ul>
<li>A first: signal(count is 1) -&gt; then B runs(count is 0) -&gt; A(this is what we want)</li>
<li>B first: wait(count &lt; 0, sleep) -&gt; A runs, wake up B(still what we want)</li>
</ul>
</li>
</ul>
<p><strong>Semaphore implementation of a Mutex</strong></p>
<ul>
<li>Mutex is short for Mutual Exclusion<ul>
<li>Can also be called a lock</li>
</ul>
</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">semaphore mutex;</span><br><span class="line">mutex.count = <span class="number">1</span>; <span class="comment">/* init the mutex */</span></span><br><span class="line">wait(mutex); <span class="comment">/* enter the critical region */</span></span><br><span class="line">Blahblah();</span><br><span class="line">signal(mutex); <span class="comment">/* exit the critical region */</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>Notice that the inital count determines how mant waits can progress before blocking and requiring a signal =&gt; mutex.count initialised as 1</p>
</blockquote>
<p><strong>Solve the producer-consumer problem</strong></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> N = 4;</span></span><br><span class="line">semaphore mutex = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* count empty slots */</span></span><br><span class="line">semaphore empty = N</span><br><span class="line"></span><br><span class="line"><span class="comment">/* count full slots */</span></span><br><span class="line">semaphore full = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">prod() &#123;</span><br><span class="line">	<span class="keyword">while</span>(TRUE) &#123;</span><br><span class="line">		item = produce()</span><br><span class="line">		wait(empty);</span><br><span class="line">		wait(mutex)</span><br><span class="line">		insert_item();</span><br><span class="line">		signal(mutex);</span><br><span class="line">		signal(full);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">con() &#123;</span><br><span class="line">	<span class="keyword">while</span>(TRUE) &#123;</span><br><span class="line">		wait(full);</span><br><span class="line">		wait(mutex);</span><br><span class="line">		remove_item();</span><br><span class="line">		signal(mutex);</span><br><span class="line">		signal(empty);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>Summary</strong></p>
<ul>
<li>Semaphores can be used to solve a varity of concurrency problems</li>
<li>However, programming with then can be error-prone<ul>
<li>E.g. must signal for every wait for mutexes<ul>
<li>Too many or few signals or waits, or signals and waits in the wrong order, can have catastrophic results</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Monitors"><a href="#Monitors" class="headerlink" title="Monitors"></a>Monitors</h3><ul>
<li>To ease concurrent programming, Hoare(1974) proposed monitors<ul>
<li>A higher level synchronisation primitive</li>
<li>Programming language construct</li>
</ul>
</li>
<li>Idea<ul>
<li>A set of procedures, variables, data types are grouped in a special kind of module, a monitor.<ul>
<li>Variables and data types only accessed from within the monitor</li>
</ul>
</li>
<li>Only one process/thread can be in the monitor at any one time<ul>
<li>Mutual exclusion is implemented by the compiler(which should be less error prone)<br><img src="https://i.loli.net/2020/08/11/bDZvzo62eSswWGC.png" alt="monitor"></li>
</ul>
</li>
</ul>
</li>
<li>When a thread calls a monitor procedure that has a thread already inside, it is queued and it sleeps until the current thread exits the monitor<br><strong>example</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">monitor exmaple</span><br><span class="line">	integer i;</span><br><span class="line">	condition c;</span><br><span class="line"></span><br><span class="line">	procedure producer();</span><br><span class="line">	.</span><br><span class="line">	.</span><br><span class="line">	.</span><br><span class="line">	end;</span><br><span class="line"></span><br><span class="line">	procedure consumer();</span><br><span class="line">	.</span><br><span class="line">	.</span><br><span class="line">	.</span><br><span class="line">	end;</span><br><span class="line">end monitor;</span><br></pre></td></tr></table></figure>

<p><strong>How do we block waiting for an event?</strong></p>
<ul>
<li>We need a mechanism to block waiting for an event( in addition to ensuring mutual exclusion)<ul>
<li>for producer consumer problem, when buffer is empty or full</li>
</ul>
</li>
<li>Condition variables<ul>
<li>To allow a process to wait within the monitor, a condition variable must be declared, as <code>condition x, y</code></li>
<li>Condition variable can only be used with the operations wait and sigal<ul>
<li>The operation <code>x.wait()</code>;<ul>
<li>means that the process invoking this operation is suspended until another process invokes </li>
<li>Another thread can enter the monitor while original is suspended</li>
</ul>
</li>
<li><code>x.signal();</code><ul>
<li>The operation resumes exactly on suspended process. If no process is suspended, then the signal opeartion has no effect.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="The-Readers-and-Writers-Problem"><a href="#The-Readers-and-Writers-Problem" class="headerlink" title="The Readers and Writers Problem"></a>The Readers and Writers Problem</h3><ul>
<li>Models access to a data base<ul>
<li>E.g. airline reservation system</li>
<li>Can have more thant one concurrent reader<ul>
<li>To check schedules and reservations</li>
</ul>
</li>
<li>Writers must have exclusive access<ul>
<li>To book a ticket or update a schedule</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>A solution</strong></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> in semaphore; 						<span class="comment">/* use your imagination */</span></span><br><span class="line">semaphore mutex = <span class="number">1</span>;							<span class="comment">/* controls access to 'rc'*/</span></span><br><span class="line">semaphore db = <span class="number">1</span>;									<span class="comment">/* controls access to the database */</span></span><br><span class="line"><span class="keyword">int</span> rc = <span class="number">0</span>;                       <span class="comment">/* # of processes reading ot wanting to */</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">reader</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;               </span><br><span class="line">  <span class="keyword">while</span>(TRUE) &#123;                   <span class="comment">/* repeat forever */</span></span><br><span class="line">    down(&amp;mutex);                 <span class="comment">/* get exclusive access to 'rc' */</span></span><br><span class="line">    rc = rc + <span class="number">1</span>;                  <span class="comment">/* one reader more now */</span></span><br><span class="line">    <span class="keyword">if</span>(rc == <span class="number">1</span>) down(&amp;db);        <span class="comment">/* if this is the first reader */</span></span><br><span class="line">    up(&amp;mutex);                   <span class="comment">/* release exclusive access to 'rc' */</span></span><br><span class="line">    read_data_base();             <span class="comment">/* access the data */</span></span><br><span class="line">    down(&amp;mutex);                 <span class="comment">/* get exclusive access to 'rc' */</span></span><br><span class="line">    rc = rc - <span class="number">1</span>;                  <span class="comment">/* one reader fewer now */</span></span><br><span class="line">    <span class="keyword">if</span>(rc == <span class="number">0</span>) up(&amp;db);          <span class="comment">/* if this is the last reader */</span></span><br><span class="line">    up(&amp;mutex);                   <span class="comment">/* release exclusive access to 'rc */</span></span><br><span class="line">    use_data_read();              <span class="comment">/* noncritical region */</span></span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">writer</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123; </span><br><span class="line">    <span class="keyword">while</span> (TRUE) &#123;                <span class="comment">/* repeat forever */</span></span><br><span class="line">      think_up_date();            <span class="comment">/* noncritical regionn */</span></span><br><span class="line">      down(&amp;db);                  <span class="comment">/* get exclusive access */</span></span><br><span class="line">      wirte_data_base();          <span class="comment">/* update the data */</span></span><br><span class="line">      up(&amp;db);                    <span class="comment">/* release exclusive access */</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h1 id="Deadlock"><a href="#Deadlock" class="headerlink" title="Deadlock"></a>Deadlock</h1><h2 id="Resources"><a href="#Resources" class="headerlink" title="Resources"></a>Resources</h2><ul>
<li>Examples of computer resources<ul>
<li>printers</li>
<li>tape drives</li>
<li>Tables in a database</li>
</ul>
</li>
<li>Processes need access to resources in reasonable order</li>
<li>Preemptable resources<ul>
<li>e.g. virtual memory</li>
<li>can be taken away from a process with no ill effects</li>
</ul>
</li>
<li>Nonpreemtable resources<ul>
<li>will cause the process to fail if take away </li>
</ul>
</li>
</ul>
<h4 id="Resources-amp-Deadlocks"><a href="#Resources-amp-Deadlocks" class="headerlink" title="Resources &amp; Deadlocks"></a>Resources &amp; Deadlocks</h4><ul>
<li>Suppose a process holds resource A and requests resource B<ul>
<li>at same time another process holds B and requests A</li>
<li>both are blocked and remain so – <strong>Deadlock</strong></li>
</ul>
</li>
<li>Deadlocks occur when …<ul>
<li>processes are granted exclusive access to devices, locks, tables, etc..</li>
<li>we refer to these entities generally as resources</li>
</ul>
</li>
</ul>
<h4 id="Resource-Access"><a href="#Resource-Access" class="headerlink" title="Resource Access"></a>Resource Access</h4><ul>
<li>Sequence of events required to use a resource</li>
</ul>
<ol>
<li>request the resource</li>
<li>use the resource</li>
<li>release the resource</li>
</ol>
<ul>
<li>Must wait if request is denied<ul>
<li>requesting process may  be blocked</li>
<li>may fail with error code</li>
</ul>
</li>
</ul>
<h2 id="Deadlock-1"><a href="#Deadlock-1" class="headerlink" title="Deadlock"></a>Deadlock</h2><blockquote>
<p>A set of processes is deadlocked if each process in the set is waiting for an event that only another process in the set can cause.</p>
</blockquote>
<ul>
<li>Usually the event is release of a currently held resource</li>
<li>None of the processes can …<ul>
<li>run </li>
<li>release resources</li>
<li>be awakened</li>
</ul>
</li>
</ul>
<h4 id="Four-Conditions-for-Deadlock"><a href="#Four-Conditions-for-Deadlock" class="headerlink" title="Four Conditions for Deadlock"></a>Four Conditions for Deadlock</h4><ol>
<li>Mutual exclusion condition<ul>
<li>each resource assigned to 1 process or is available</li>
</ul>
</li>
<li>Hold and wait condition<ul>
<li>process holding resources can request additional</li>
</ul>
</li>
<li>No preemption condition<ul>
<li>previously granted resources cannot be forcibly taken away</li>
</ul>
</li>
<li>Circular wait condition<ul>
<li>must be a circular chain of 2 or more processes</li>
<li>each is waiting for resource held by next member of the chain</li>
</ul>
</li>
</ol>
<h4 id="Strategies-for-dealing-with-Deadlocks"><a href="#Strategies-for-dealing-with-Deadlocks" class="headerlink" title="Strategies for dealing with Deadlocks"></a>Strategies for dealing with Deadlocks</h4><ol>
<li><p>Just ignore the problem altogether</p>
</li>
<li><p>prevention</p>
<p>​      Negating one of the four necessary conditions</p>
</li>
<li><p>Detection and recovery</p>
</li>
<li><p>Dynamic avoidance</p>
<p>​      Careful resource allocation</p>
</li>
</ol>
<p><strong>Appoarch 1: The Ostrich Algorithm</strong></p>
<ul>
<li>Pretend there is no problem</li>
<li>Reasonable if <ul>
<li>deadlocks occur very rarely</li>
<li>Cost of prevention is high<ul>
<li>Example of “cost”, only one process runs at a time</li>
</ul>
</li>
</ul>
</li>
<li>UNIX and Windows takes this approach for some of the more complex resource relationships they manage</li>
<li>It’s a trade off between<ul>
<li>Convenience (engineering approach)</li>
<li>Correctness(mathematical approach) </li>
</ul>
</li>
</ul>
<p><strong>Approach 2: Deadlock Prevention</strong></p>
<blockquote>
<p>The most common used strategy</p>
</blockquote>
<p>Resource allocation rules prevent deadlock by prevent one of the four condition required for deadlock from occuring</p>
<ul>
<li><p>Mutual exclusion</p>
<ul>
<li>Not feasible in general<ul>
<li>Some devices/resource are intrinsically not shareable</li>
</ul>
</li>
</ul>
</li>
<li><p>Hold and wait</p>
<ul>
<li><p>Require processes to request resources before starting</p>
<ul>
<li>a process never has to wait for what it needs</li>
</ul>
</li>
<li><p>Issues </p>
<ul>
<li><p>may not know required resources at start of run</p>
<ul>
<li><blockquote>
<p>must be determined at run time or by user input(e.g. using Word to open a file)</p>
</blockquote>
</li>
<li><p>$\Rightarrow$ not always possible</p>
</li>
</ul>
</li>
<li><p>Also ties up resources other processes could be using</p>
</li>
</ul>
</li>
<li><p>Varitions:</p>
<ul>
<li><p>Process must give up all resources if it would block holding a resource</p>
</li>
<li><p>then request all immediately needed</p>
</li>
<li><p>prone to livelock</p>
<ul>
<li><blockquote>
<p>Livelocked processes are not blocked, change state regularly, but never make progress.</p>
</blockquote>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>No preemption</p>
<ul>
<li>This is not a viable option</li>
</ul>
</li>
<li><p>Circular Wait</p>
<ul>
<li>aquire resource in the same order, order resources</li>
</ul>
</li>
</ul>
<p><strong>Approach 3: Detection and Recovery</strong></p>
<ul>
<li>Need a method to determine if a system is deadlocked</li>
<li>Assuming deadlocked is detected, we need a method of recorvery to restore progress to the system.</li>
</ul>
<p><em>Modeling resources and processes as a directed graph</em><img src="https://i.loli.net/2020/08/11/LQtb9AFBuiUDM4v.png" alt=""></p>
<p>(a) represents everthing in the system</p>
<p>(b) is a deadlock</p>
<p><code>What about resources with multiple units?</code></p>
<ul>
<li>Some examples of multi-unit resources<ul>
<li>RAM</li>
<li>Blocks on a hard disk drive</li>
<li>Slots in a buffer</li>
</ul>
</li>
<li>We need an approach for dealing with resources that consists of more than a single unit</li>
</ul>
<p><em>Modeling using matrix</em></p>
<p><img src="https://i.loli.net/2020/08/11/8mCWRXsqgQeTMV9.png" alt=""></p>
<p>Data structured needed by deadlock detection algorithm</p>
<p>sum of current resource allocation + resources available = resources that exist<br>$$<br>\sum_{i=1}^{n}{C_{ij}}+A_j = E_j<br>$$<br><code>Example</code></p>
<p><img src="https://i.loli.net/2020/08/11/4FdkPJrNBqoZp6E.png" alt=""></p>
<ul>
<li>Process 1: has 1 scanners</li>
<li>Process 2: has 2 tape drivers and 1 CD roms</li>
<li>Process 3: has 1 plotters and 2 scanners</li>
</ul>
<p><em>Detection Algoritm</em></p>
<ul>
<li>Look for an unmarked process $Pi$, for which the $i$-th row of R is less than equal to A</li>
<li>If found, add the $i$-th row of C to A, and mark $Pi$. Got to step 1</li>
<li>If no such process exists, terminate</li>
</ul>
<p>Remaining processes are deadlocked.</p>
<p>Recovery from Deadlock</p>
<ul>
<li>Recovery through preemption<ul>
<li>Take a resource from some other process</li>
<li>Depends on nature of the resource</li>
</ul>
</li>
<li>Recovery through rollback<ul>
<li>Checkpoint a process periodically<ul>
<li>not come for free, not practical</li>
</ul>
</li>
<li>Use this saved state</li>
<li>Restart the process if it is found deadlocked<ul>
<li>No guarantee is won’t deadlock again</li>
</ul>
</li>
</ul>
</li>
<li>Recovery through killing processes<ul>
<li>Crudest but simplest way to break a deadlock</li>
<li>Kill one of the processes in the deadlock cycle</li>
<li>The other processes get its resources</li>
<li>Choose process that can be rerun from the beginning</li>
</ul>
</li>
</ul>
<p><strong>Approach 4 Deadlock Avoidance</strong></p>
<blockquote>
<p>Not practical for all systems, need to know enough information in advance</p>
</blockquote>
<p><img src="https://i.loli.net/2020/08/11/21zuAcOstYon6U4.png" alt="Two process resource trajectories"></p>
<p><em>Safe and Unsafe States</em></p>
<ul>
<li>A state is safe if<ul>
<li>The system is not deadlocked </li>
<li>There exists a scheduling order that results in every process running to completion, even if they all request their maximum resources immediately</li>
</ul>
</li>
</ul>
<ul>
<li>Unsafe states are not necessarily deadlocked<ul>
<li>with a lucky sequence, all processes may complete</li>
<li>However, we cannot guarantee that they will complete(not deadlock)</li>
</ul>
</li>
<li>Safe states guarantee we will eventually complete all processes</li>
<li>Deadlock avoidance algorithm<ul>
<li>Only grant requests that result in safe states</li>
</ul>
</li>
</ul>
<p><em>Bankers Algorithm</em></p>
<ul>
<li>Modelled on a Banker with Customers<ul>
<li>The banker has a limited amount of money to loan customers<ul>
<li>Limited number of resources</li>
</ul>
</li>
<li>Each customer can borrow money up to the customer’s credit limit<ul>
<li>Maximum number of resources required</li>
</ul>
</li>
</ul>
</li>
<li>Basic idea<ul>
<li>keep the bank in a safe state<ul>
<li>So all customers are happy even if they all request to borrow up to their credit limit at the same time</li>
</ul>
</li>
<li>Customers wishing to borrow such that the back would enter an unsafe state must wait until somebody else repays their loan such that the transaction becomes safe.</li>
</ul>
</li>
<li>Bankers Algorithm is not commonly used in practice<ul>
<li>It is difficult (sometimes impossible ) to know in advance<ul>
<li>the resources a process will require</li>
<li>the number of processes in a dynamic system</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="Starvation"><a href="#Starvation" class="headerlink" title="Starvation"></a>Starvation</h4><blockquote>
<p>A process never receives the resource it is waiting for, despite the resource(repeatedly) becoming free, the resource is always allocated to another waiting process.</p>
</blockquote>
<p>One solution: First-come, first-serve policy</p>
<h1 id="System-Call"><a href="#System-Call" class="headerlink" title="System Call"></a>System Call</h1><h2 id="System-Calls"><a href="#System-Calls" class="headerlink" title="System Calls"></a>System Calls</h2><ul>
<li>Can be viewed as special function calls<ul>
<li>Provides for a controlled entry into the kernel</li>
<li>While in kernel, they perform a privileged operation</li>
<li>Returns to original caller with the result</li>
</ul>
</li>
<li>The system call interface represents the abstract machine provided by the operating system.</li>
</ul>
<h3 id="A-brief-overview"><a href="#A-brief-overview" class="headerlink" title="A brief overview"></a>A brief overview</h3><p>From the user’s perspective </p>
<ul>
<li>Process Management</li>
<li>File I/O </li>
<li>Dirctories management</li>
<li>Some other selected Calls</li>
<li>There are many more <ul>
<li>On Linux, see man syscalls for a list</li>
</ul>
</li>
</ul>
<h4 id="Process-Management"><a href="#Process-Management" class="headerlink" title="Process Management"></a>Process Management</h4><table>
<thead>
<tr>
<th>Call</th>
<th>Descritption</th>
</tr>
</thead>
<tbody><tr>
<td>pid=fork()</td>
<td>Create a child process identical to the parent</td>
</tr>
<tr>
<td>Pid = waitpid(pid, &amp;statloc, options)</td>
<td>Wait for a child to terminate</td>
</tr>
<tr>
<td>s = execve(name, argv, environp)</td>
<td>Replace a process’ core image</td>
</tr>
<tr>
<td>exit(status)</td>
<td>Terminate process execution and return status</td>
</tr>
</tbody></table>
<h4 id="File-Management"><a href="#File-Management" class="headerlink" title="File Management"></a>File Management</h4><table>
<thead>
<tr>
<th>Call</th>
<th>Descrition</th>
</tr>
</thead>
<tbody><tr>
<td>fd=open(file, how, …,)</td>
<td>Open a file for reading, writing or both</td>
</tr>
<tr>
<td>s = close(fd)</td>
<td>Close an open file</td>
</tr>
<tr>
<td>n = read(fd, buffer, bytes)</td>
<td>Read data from a file into a buffer</td>
</tr>
<tr>
<td>n = write(fd, buffer, bytes)</td>
<td>Write data from a buffer into a file</td>
</tr>
<tr>
<td>Position = lseek(fd, offset, whence)</td>
<td>Move the file pointer</td>
</tr>
<tr>
<td>s = stat(name, &amp;buf)</td>
<td>Get a file’s status information</td>
</tr>
</tbody></table>
<h4 id="A-stripped-down-shell"><a href="#A-stripped-down-shell" class="headerlink" title="A stripped down shell:"></a>A stripped down shell:</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span>(TRUE) &#123;                       <span class="comment">/* repeat forever */</span></span><br><span class="line">  type_prompt();                    <span class="comment">/* display prompt */</span></span><br><span class="line">  read_command(command, parameters);</span><br><span class="line">  <span class="keyword">if</span> (fork() != <span class="number">0</span>) &#123;                <span class="comment">/* fork off child process*/</span></span><br><span class="line">    <span class="comment">/* Parent code */</span></span><br><span class="line">    waitpid(<span class="number">-1</span>, &amp;status, <span class="number">0</span>);        <span class="comment">/* wait for child to exit */</span></span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">/* Child code */</span></span><br><span class="line">    execve(command, parameters, <span class="number">0</span>); <span class="comment">/* execute command */</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h2 id="System-Call-Implementation"><a href="#System-Call-Implementation" class="headerlink" title="System Call Implementation"></a>System Call Implementation</h2><h4 id="A-Simple-Model-of-CPU-Computation"><a href="#A-Simple-Model-of-CPU-Computation" class="headerlink" title="A Simple Model of CPU Computation"></a>A Simple Model of CPU Computation</h4><p><img src="https://i.loli.net/2020/08/11/CcVnqFvNhegibot.jpg" alt="">The fetch-execute cycle </p>
<ul>
<li>Load memory contents from address in program counter (PC)<ul>
<li>The instruction</li>
</ul>
</li>
<li>Execute the instruction</li>
<li>increment PC</li>
<li>Repeat</li>
</ul>
<h3 id="A-Simple-Model-of-CPU-Computation-1"><a href="#A-Simple-Model-of-CPU-Computation-1" class="headerlink" title="A Simple Model of CPU Computation"></a>A Simple Model of CPU Computation</h3><ul>
<li><p>Stack Pointer(SP)</p>
</li>
<li><p>Status Register</p>
</li>
</ul>
<ul>
<li><p>Condition codes</p>
<ul>
<li>Positive result</li>
<li>Zero result</li>
<li>Negative result</li>
</ul>
</li>
<li><p>General Purpose Register</p>
<ul>
<li>Holds operands of most instructions</li>
<li>Enables programmers (compiler) to minmise memory reference</li>
</ul>
</li>
</ul>
<h4 id="Privileged-mode-Operation"><a href="#Privileged-mode-Operation" class="headerlink" title="Privileged-mode Operation"></a>Privileged-mode Operation</h4><p>To protect operating system execution, two or more CPU modes of operation exist </p>
<ul>
<li>Privileged mode(system, kernel-mode)<ul>
<li>All instructions and register are available</li>
</ul>
</li>
<li>User-mode<ul>
<li>Users ‘safe’ subset of instruction set<ul>
<li>Only affects the state of the application itself</li>
<li>They cannot be used to uncontrollably interference with OS</li>
</ul>
</li>
<li>Only ‘safe’ registers are accessible</li>
</ul>
</li>
</ul>
<h3 id="System-Call-1"><a href="#System-Call-1" class="headerlink" title="System Call"></a>System Call</h3><h4 id="System-Call-Mechanism-Overview"><a href="#System-Call-Mechanism-Overview" class="headerlink" title="System Call Mechanism Overview"></a>System Call Mechanism Overview</h4><ul>
<li>System call transitions triggered by special processor instructions<ul>
<li>User to Kernel<ul>
<li>System call instruction</li>
</ul>
</li>
<li>Kernel to User<ul>
<li>Return from privileged mode instruction</li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li>Processor mode<ul>
<li>Switched from user-mode to kernel-mode<ul>
<li>Switched back when returning to user mode</li>
</ul>
</li>
</ul>
</li>
<li>Stack Pointer (SP)<ul>
<li>User-level SP is saved and a kernel SP is initialised<ul>
<li>User-level SP restored when returning to user-mode</li>
</ul>
</li>
</ul>
</li>
<li>Program Counter (PC)<ul>
<li>User-level PC is saved and PC set to kernel entry point<ul>
<li>User-level PC restored when returning to user-level</li>
</ul>
</li>
<li>Kernel entry via the designated entry point must be strictly enforced</li>
</ul>
</li>
<li>Registers<ul>
<li>Set at user-level to indicate system call type and its arguments<ul>
<li>A convention between applications and the kernel</li>
</ul>
</li>
<li>Some registers are preserved at user-level or kernel-level in order to restart user-level execution<ul>
<li>Depends on language calling convention etc</li>
</ul>
</li>
<li>Result of system call placed in registers when returning to user-level<ul>
<li>Another convention</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>Why do we need system calls?</strong></p>
<p>Why not simply jump into the kernel via a function call????</p>
<p>Function calls do not</p>
<ul>
<li>Change from user to kernel mode<ul>
<li>and eventually back again</li>
</ul>
</li>
<li>Restrict possible entry points to secure locations<ul>
<li>To prevent entering after any security checks </li>
</ul>
</li>
</ul>
<h4 id="Steps-in-Making-a-System-Call"><a href="#Steps-in-Making-a-System-Call" class="headerlink" title="Steps in Making a System Call"></a>Steps in Making a System Call</h4><p><img src="https://i.loli.net/2020/08/11/3Zor8IVpRyS9CB4.jpg" alt=""></p>
<h1 id="File-Management-1"><a href="#File-Management-1" class="headerlink" title="File Management"></a>File Management</h1><h2 id="Overview-of-the-FS-abstraction"><a href="#Overview-of-the-FS-abstraction" class="headerlink" title="Overview of the FS abstraction"></a>Overview of the FS abstraction</h2><table>
<thead>
<tr>
<th>User’s view</th>
<th>Under the hood</th>
</tr>
</thead>
<tbody><tr>
<td>Uniform namespace</td>
<td>Heterogenrous collection of storage devices</td>
</tr>
<tr>
<td>Hierachical structure</td>
<td>Flat address space(block numbers)</td>
</tr>
<tr>
<td>Arbitrarily-sized files</td>
<td>Fixed-size blocks</td>
</tr>
<tr>
<td>Symbolic file names</td>
<td>Numeric block addresses</td>
</tr>
<tr>
<td>Access control</td>
<td>No access control</td>
</tr>
<tr>
<td>Tools for (formatting, defragmentation, Backup, Consistency checking)</td>
<td></td>
</tr>
</tbody></table>
<h2 id="File-Names"><a href="#File-Names" class="headerlink" title="File Names"></a>File Names</h2><p>File system must provide a convenient naming scheme</p>
<ul>
<li>Textual Names </li>
<li>May have restrictions <ul>
<li>Only certain characters</li>
<li>Limited length</li>
<li>Only certain format</li>
</ul>
</li>
<li>Case (in)sensitive</li>
<li>Names may obey conventions<ul>
<li>Interpreted by tools</li>
<li>interpreted by operating system</li>
</ul>
</li>
</ul>
<h2 id="File-Structure"><a href="#File-Structure" class="headerlink" title="File Structure"></a>File Structure</h2><p>Sequence of Bytes</p>
<ul>
<li>OS consider a file to be unstructured</li>
<li>Applications can impose their own structure</li>
<li>Used by UNIX, Window, most modern OSes</li>
</ul>
<h2 id="File-Types"><a href="#File-Types" class="headerlink" title="File Types"></a>File Types</h2><p>Regular File</p>
<p>Directories</p>
<p>Device Files</p>
<ul>
<li>May be divided into<ul>
<li>Character Devices – stream of bytes</li>
<li>Block Devices</li>
</ul>
</li>
<li>Some systems distinguish between regular file types <ul>
<li>ASCII text files, binary files</li>
</ul>
</li>
</ul>
<h2 id="File-Access-Types-Patterns"><a href="#File-Access-Types-Patterns" class="headerlink" title="File Access Types(Patterns)"></a>File Access Types(Patterns)</h2><p>Sequential access </p>
<ul>
<li>read all bytes/records from the beginning </li>
<li>cannot jump around, could rewind or back up </li>
<li>convenient when medium was magnetic tape </li>
</ul>
<p>Random access </p>
<ul>
<li>bytes/records read in any order </li>
<li>essential for data base systems </li>
<li>read can be … <ul>
<li>move file pointer (seek), then read or <ul>
<li>lseek(location,…);read(…) </li>
</ul>
</li>
<li>each read specifies the file pointer <ul>
<li>read(location,…) 11</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Typical-File-Operations"><a href="#Typical-File-Operations" class="headerlink" title="Typical File Operations"></a>Typical File Operations</h3><p><code>Create</code> <code>Delete</code> <code>Open</code> <code>Close</code> <code>Read</code>  <code>Write</code> <code>Append</code> <code>Rename</code> <code>Seek</code> <code>Get attributes</code> <code>Set Attributes</code> </p>
<h3 id="File-Organisation-and-Access"><a href="#File-Organisation-and-Access" class="headerlink" title="File Organisation and Access"></a>File Organisation and Access</h3><p>(Programmer’s Perspective)</p>
<p>Given an operating system supporting unstructured files that are a stream-of-bytes,how can one organise the contents of the files?</p>
<p>E.g. Executable Linkable Format (ELF)</p>
<p>Some possible access patterns: </p>
<ul>
<li>Read the whole file –Read individual records from a file  </li>
<li>record = sequence of bytes containing the record </li>
<li>Read records preceding or following the current one </li>
<li>Retrieve a set of records </li>
<li>Write a whole file sequentially </li>
<li>Insert/delete/update records in a file </li>
</ul>
<p>Programmers are free to structure the file to suit the application</p>
<h3 id="Criteria-for-File-Organization"><a href="#Criteria-for-File-Organization" class="headerlink" title="Criteria for File Organization"></a>Criteria for File Organization</h3><p>Things to consider when designing file layout </p>
<ul>
<li>Rapid access <ul>
<li>Needed when accessing a single record </li>
<li>Not needed for batch mode <ul>
<li>read from start to finish </li>
</ul>
</li>
</ul>
</li>
<li>Ease of update <ul>
<li>File on CD-ROM will not be updated, so this is not a concern </li>
</ul>
</li>
<li>Economy of storage <ul>
<li>Should be minimum redundancy in the data </li>
<li>Redundancy can be used to speed access such as an index</li>
</ul>
</li>
</ul>
<h3 id="File-Directories"><a href="#File-Directories" class="headerlink" title="File Directories"></a>File Directories</h3><p>Provide mapping between file names and the files themselves </p>
<p>Contain information about files </p>
<ul>
<li>Attributes </li>
<li>Location </li>
<li>Ownership </li>
</ul>
<p>Directory itself is a file owned by the operating system</p>
<h3 id="Hierarchical-Tree-Structured-Directory"><a href="#Hierarchical-Tree-Structured-Directory" class="headerlink" title="Hierarchical (Tree-Structured) Directory"></a>Hierarchical (Tree-Structured) Directory</h3><p>Files can be located by following a path from the root, or master, directory down various branches</p>
<ul>
<li>This is the absolute pathname for the file</li>
</ul>
<p>Can have several files with the same file name as long as they have unique path names</p>
<h3 id="Current-Working-Directory"><a href="#Current-Working-Directory" class="headerlink" title="Current Working Directory"></a>Current Working Directory</h3><p>Always specifying the absolute pathname for a file is tedious!</p>
<p>Introduce the idea of a working directory</p>
<ul>
<li>Files are referenced relative to the working directory</li>
</ul>
<h3 id="Relative-and-Absolute-Pathnames"><a href="#Relative-and-Absolute-Pathnames" class="headerlink" title="Relative and Absolute Pathnames"></a>Relative and Absolute Pathnames</h3><p>Absolute pathname</p>
<ul>
<li>A path specified from the root of the file system to the file</li>
</ul>
<p>A Relative pathname</p>
<ul>
<li>A pathname specified from the cwd</li>
</ul>
<p>Note: ‘.’ (dot) and ‘..’ (dotdot) refer to current and parent directory</p>
<h3 id="Typical-Directory-Operations"><a href="#Typical-Directory-Operations" class="headerlink" title="Typical Directory Operations"></a>Typical Directory Operations</h3><p><code>Create</code> <code>Delete</code> <code>Opendir</code> <code>Closedir</code> <code>Readdir</code> <code>Rename</code> <code>Link</code> <code>Unlink</code></p>
<h3 id="Nice-properties-of-UNIX-naming"><a href="#Nice-properties-of-UNIX-naming" class="headerlink" title="Nice properties of UNIX naming"></a>Nice properties of UNIX naming</h3><p>Simple, regular format </p>
<ul>
<li>Names referring to different servers, objects, etc., have the same syntax. <ul>
<li>Regular tools can be used where specialised tools would be otherwise be needed. </li>
</ul>
</li>
</ul>
<p>Location independent </p>
<ul>
<li>Objects can be distributed or migrated, and continue with the same names.</li>
</ul>
<h3 id="File-Sharing"><a href="#File-Sharing" class="headerlink" title="File Sharing"></a>File Sharing</h3><p>In multiuser system, allow files to be shared among users</p>
<p>Two issues</p>
<ul>
<li>Access rights<ul>
<li>None<ul>
<li>User may not know of the existence of the file</li>
<li>User is not allowed to read the directory that includes the file</li>
</ul>
</li>
<li>Knowledge<ul>
<li>User can only determine that the file exists and who its owner is</li>
</ul>
</li>
<li>Execution<ul>
<li>The user can load and execute a program but cannot copy it</li>
</ul>
</li>
<li>Reading<ul>
<li>The user can read the file for any purpose, including copying and execution</li>
</ul>
</li>
<li>Appending<ul>
<li>The user can add data to the file but cannot modify or delete any of the file’s contents</li>
</ul>
</li>
<li>Updating<ul>
<li>The user can modify, delete, and add to the file’s data. This includes creating the file, rewriting it, and removing all or part of the data</li>
</ul>
</li>
<li>Changing protection<ul>
<li>User can change access rights granted to other users</li>
</ul>
</li>
<li>Deletion<ul>
<li>User can delete the file</li>
</ul>
</li>
<li>Owners<ul>
<li>Has all rights previously listed</li>
<li>May grant rights to others using the following classes of users<ul>
<li>Specific user</li>
<li>User groups</li>
<li>All for public files</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Management of simultaneous access<ul>
<li>Most OSes provide mechanisms for users to manage concurrent access to files<ul>
<li>Example: flock(), lockf(), system calls</li>
</ul>
</li>
<li>Typically<ul>
<li>User may lock entire file when it is to be updated</li>
<li>User may lock the individual records (i.e. ranges) during the update</li>
</ul>
</li>
<li>Mutual exclusion and deadlock are issues for shared access</li>
</ul>
</li>
</ul>
<h1 id="File-System"><a href="#File-System" class="headerlink" title="File System"></a>File System</h1><ul>
<li><p>The FS must map symbolic file names into a collection of block addresses</p>
</li>
<li><p>The FS must keep track of</p>
<ul>
<li>which blocks belong to which files</li>
<li>in what order the blocks form the file</li>
<li>which blocks are free for allocation</li>
</ul>
</li>
<li><p>Given a logical region of a file, the FS must track the corresponding block(s) on disk</p>
<ul>
<li>Stored in file system metadata</li>
</ul>
</li>
</ul>
<h2 id="File-Allocation-Methods"><a href="#File-Allocation-Methods" class="headerlink" title="File Allocation Methods"></a>File Allocation Methods</h2><blockquote>
<p>A file is divided into “blocks” – the unit of transfer to storage</p>
</blockquote>
<h3 id="External-and-internal-fragmentation"><a href="#External-and-internal-fragmentation" class="headerlink" title="External and internal fragmentation"></a>External and internal fragmentation</h3><h4 id="External-fragmentation"><a href="#External-fragmentation" class="headerlink" title="External fragmentation"></a>External fragmentation</h4><ul>
<li>The space wasted external to the allocated memory regions</li>
<li>Memory space exists to satisfy a request but it is unusable as it is not contiguous</li>
</ul>
<h4 id="Internal-fragmentation"><a href="#Internal-fragmentation" class="headerlink" title="Internal fragmentation"></a>Internal fragmentation</h4><ul>
<li>The space wasted internal to the allocated memory regions</li>
<li>Allocated memory may be slightly larger than requested memory; this size difference is wasted memory internal to a partition</li>
</ul>
<h3 id="Contiguous-Allocation"><a href="#Contiguous-Allocation" class="headerlink" title="Contiguous Allocation"></a>Contiguous Allocation</h3><p><span class="emoji" alias="white_check_mark" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2705.png?v8">&#x2705;</span> Easy bookkeeping (need to keep track of the starting block and length of the file)</p>
<p><span class="emoji" alias="white_check_mark" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2705.png?v8">&#x2705;</span> Increases performance for sequential operations</p>
<p><span class="emoji" alias="x" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/274c.png?v8">&#x274c;</span> Need the maximum size for the file at the time of creation</p>
<p><span class="emoji" alias="x" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/274c.png?v8">&#x274c;</span> As files are deleted, free space becomes divided into many small chunks (external fragmentation)</p>
<h3 id="Dynamic-Allocation-Strategies"><a href="#Dynamic-Allocation-Strategies" class="headerlink" title="Dynamic Allocation Strategies"></a>Dynamic Allocation Strategies</h3><blockquote>
<p>Disk space allocated in portions as needed</p>
<p> Allocation occurs in fixed-size blocks</p>
</blockquote>
<p><span class="emoji" alias="white_check_mark" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2705.png?v8">&#x2705;</span> No external fragmentation</p>
<p><span class="emoji" alias="white_check_mark" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2705.png?v8">&#x2705;</span> Does not require pre-allocating disk space</p>
<p><span class="emoji" alias="x" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/274c.png?v8">&#x274c;</span> Partially filled blocks (internal fragmentation)</p>
<p><span class="emoji" alias="x" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/274c.png?v8">&#x274c;</span> File blocks are scattered across the disk</p>
<p><span class="emoji" alias="x" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/274c.png?v8">&#x274c;</span> Complex metadata management (maintain the collection of blocks for each file)</p>
<h4 id="Dynamic-allocation-Linked-list-allocation"><a href="#Dynamic-allocation-Linked-list-allocation" class="headerlink" title="Dynamic allocation: Linked list allocation"></a>Dynamic allocation: Linked list allocation</h4><blockquote>
<p>Each block contains a pointer to the next block in the chain. Free blocks are also linked in a chain.</p>
</blockquote>
<p><span class="emoji" alias="white_check_mark" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2705.png?v8">&#x2705;</span> Only single metadata entry per file </p>
<p><span class="emoji" alias="white_check_mark" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2705.png?v8">&#x2705;</span> Best for sequential files </p>
<p><span class="emoji" alias="x" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/274c.png?v8">&#x274c;</span> Poor for random access</p>
<p><span class="emoji" alias="x" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/274c.png?v8">&#x274c;</span> Blocks end up scattered across the disk due to free list eventually being randomised</p>
<h4 id="Dynamic-Allocation-File-Allocation-Table-FAT"><a href="#Dynamic-Allocation-File-Allocation-Table-FAT" class="headerlink" title="Dynamic Allocation: File Allocation Table (FAT)"></a>Dynamic Allocation: File Allocation Table (FAT)</h4><p>Keep a map of the entire FS in a separate table</p>
<ul>
<li>A table entry contains the number of the next block of the file</li>
<li>The last block in a file and empty blocks are marked using reserved values</li>
</ul>
<p>The table is stored on the disk and is replicated in memory</p>
<p><span class="emoji" alias="white_check_mark" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2705.png?v8">&#x2705;</span> ​Random access is fast (following the in-memory list)</p>
<p><span class="emoji" alias="x" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/274c.png?v8">&#x274c;</span> Requires a lot of memory for large disks</p>
<p><span class="emoji" alias="x" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/274c.png?v8">&#x274c;</span> Free block lookup is slow </p>
<h4 id="Dynamical-Allocation-inode-based-FS-structure"><a href="#Dynamical-Allocation-inode-based-FS-structure" class="headerlink" title="Dynamical Allocation: inode-based FS structure"></a>Dynamical Allocation: inode-based FS structure</h4><p>Idea: separate table (index-node or i-node) for each file.</p>
<ul>
<li>Only keep table for open files in memory</li>
<li>Fast random access </li>
</ul>
<p>The most popular FS structure today</p>
<p><span class="emoji" alias="x" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/274c.png?v8">&#x274c;</span> i-nodes occupy one or several disk areas </p>
<p><span class="emoji" alias="x" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/274c.png?v8">&#x274c;</span> i-nodes are allocated dynamically, hence free-space management is required for i-nodes</p>
<ul>
<li>Use fixed-size i-nodes to simplify dynamic allocation</li>
<li>Reserve the last i-node entry for a pointer (a block number) to an extension i-node.</li>
</ul>
<p><strong>i-node implementation issues</strong></p>
<p>Free-space management</p>
<ul>
<li>Approach 1: linked list of free blocks in free blocks on disk<ul>
<li>List of all unallocated blocks</li>
<li>Background jobs can re-order list for better contiguity</li>
<li>Store in free blocks themselves<ul>
<li>Does not reduce disk capacity</li>
</ul>
</li>
<li>Only one block of pointers need be kept in the main memory</li>
</ul>
</li>
<li>Approach 2: keep bitmaps of free blocks and free i-nodes on disk<ul>
<li>Individual bits in a bit vector flags used/free blocks</li>
<li>May be too large to hold in main memory</li>
<li>Expensive to search</li>
<li>Concentrating (de)allocations in a portion of the bitmap has desirable effect of concentrating access</li>
<li>Simple to find contiguous free space</li>
</ul>
</li>
</ul>
<p><strong>Implementing directories</strong></p>
<p>Directories are stored like normal files</p>
<ul>
<li>directory entries are contained inside data blocks</li>
</ul>
<p>The FS assigns special meaning to the content of these files</p>
<ul>
<li>a directory file is a list of directory entries</li>
<li>a directory entry contains file name, attributes, and the file i-node number<ul>
<li>maps human-oriented file name to a system-oriented name</li>
</ul>
</li>
</ul>
<p><strong>Fixed-size vs variable-size directory entries</strong></p>
<ul>
<li>Fixed-size directory entries <ul>
<li>Either too small </li>
<li>Or waste too much space</li>
</ul>
</li>
<li>Variable-size directory entries <ul>
<li>Freeing variable length entries can create external fragmentation in directory blocks <ul>
<li>Can compact when block is in RAM</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>Searching Directory Listings</strong></p>
<p>Locating a file in a directory </p>
<ul>
<li>Linear scan <ul>
<li>Implement a directory cache in software to speed-up search </li>
</ul>
</li>
<li>Hash lookup </li>
<li>B-tree (100’s of thousands entries)</li>
</ul>
<p><strong>Storing file attributes</strong></p>
<p>(a) disk addresses and attributes in directory entry –FAT</p>
<p>(b)  directory in which each entry just refers to an i-node –UNIX</p>
<p><strong>Inode Contents</strong></p>
<p><em>Size</em></p>
<ul>
<li>Offset of the highest byte written </li>
</ul>
<p><em>Block count</em> </p>
<ul>
<li>Number of disk blocks used by the file. </li>
<li>Note that number of blocks can be much less than expected given the file size </li>
</ul>
<p><em>Files can be sparsely populated</em>  </p>
<ul>
<li>E.g. write(f,“hello”); lseek(f, 1000000); write(f, “world”);  </li>
<li>Only needs to store the start and end of file, not all the empty blocks in between. </li>
<li>Size = 1000005 </li>
<li>Blocks = 2 + any indirect blocks</li>
</ul>
<p><em>Direct Blocks</em></p>
<ul>
<li>Block numbers of first 12 blocks in the file</li>
<li>Most files are small – We can find blocks of file directly from the inode</li>
</ul>
<p><em>Single Indirect Block</em> – Block number of a block containing block numbers</p>
<ul>
<li>Requires two disk access to read – One for the indirect block; one for the target block</li>
<li>Max File Size – Assume 1Kbyte block size, 4 byte block numbers<ul>
<li>12 * 1K + 1K/4 * 1K = 268 KiB</li>
</ul>
</li>
<li>For large majority of files (&lt; 268 KiB), given the inode, only one or two further accesses required to read any block in file</li>
</ul>
<p><em>Double Indirect Block</em> – Block number of a block containing block numbers of blocks containing block numbers</p>
<p><em>Triple Indirect</em> </p>
<p><strong>Hard Links</strong></p>
<blockquote>
<p>Note that inodes can have more than one name -– Called a Hard Link</p>
</blockquote>
<p><strong>Symbolic links</strong></p>
<blockquote>
<p>A symbolic link is a file that contains a reference to another file or directory</p>
</blockquote>
<ul>
<li>Has its own inode and data block, which contains a path to the target file</li>
<li>Marked by a special file attribute</li>
<li>Transparent for some operations</li>
<li>Can point across FS boundaries</li>
</ul>
<h2 id="FS-reliability"><a href="#FS-reliability" class="headerlink" title="FS reliability"></a>FS reliability</h2><p>Disk writes are buffered in RAM</p>
<ul>
<li>OS crash or power outage ==&gt; lost data</li>
<li>Commit writes to disk periodically</li>
<li>Use the sync command to force a FS flush</li>
</ul>
<p>FS operations are non-atomic</p>
<ul>
<li>Incomplete transaction can leave the FS in an inconsistent state</li>
</ul>
<h2 id="Journaling-file-systems"><a href="#Journaling-file-systems" class="headerlink" title="Journaling file systems"></a>Journaling file systems</h2><ul>
<li>Keep a journal of FS updates</li>
<li>Before performing an atomic update sequence</li>
<li>write it to the journal</li>
<li>Replay the last journal entries upon an unclean shutdown</li>
</ul>
<h3 id="The-ext3-journal"><a href="#The-ext3-journal" class="headerlink" title="The ext3 journal"></a>The ext3 journal</h3><p><strong>Option1: Journal FS data structure updates</strong></p>
<p><span class="emoji" alias="white_check_mark" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2705.png?v8">&#x2705;</span> Efficient use of journal space; hence faster journaling </p>
<p><span class="emoji" alias="x" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/274c.png?v8">&#x274c;</span> Individual updates are applied separately</p>
<p><span class="emoji" alias="x" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/274c.png?v8">&#x274c;</span> The journaling layer must understand FS semantics</p>
<p><strong>Option2: Journal disk block updates</strong></p>
<blockquote>
<p>Ext3 implements Option 2</p>
</blockquote>
<p><span class="emoji" alias="x" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/274c.png?v8">&#x274c;</span> Even a small update adds a whole block to the journal</p>
<p><span class="emoji" alias="white_check_mark" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2705.png?v8">&#x2705;</span> Multiple updates to the same block can be aggregated into a single update</p>
<p><span class="emoji" alias="white_check_mark" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2705.png?v8">&#x2705;</span> The journaling layer is FSindependent (easier to implement)</p>
<h4 id="Journaling-Block-Device-JBD"><a href="#Journaling-Block-Device-JBD" class="headerlink" title="Journaling Block Device (JBD)"></a>Journaling Block Device (JBD)</h4><p>JBD interface (continued)</p>
<ul>
<li>Commit: write transaction data to the journal (persistent storage)<ul>
<li>Multiple FS transactions are committed in one go</li>
</ul>
</li>
<li>Checkpoint: flush the journal to the disk <ul>
<li>Used when the journal is full or the FS is being unmounted</li>
</ul>
</li>
</ul>
<h3 id="Trade-off-in-FS-block-size"><a href="#Trade-off-in-FS-block-size" class="headerlink" title="Trade-off in FS block size"></a>Trade-off in FS block size</h3><ul>
<li>File systems deal with 2 types of blocks<ul>
<li>Disk blocks or sectors (usually 512 bytes)</li>
<li>File system blocks 512 * 2^N bytes</li>
</ul>
</li>
<li>Larger blocks require less FS metadata</li>
<li>Smaller blocks waste less disk space (less internal fragmentation)</li>
<li>Sequential Access<ul>
<li>The larger the block size, the fewer I/O operations required</li>
</ul>
</li>
<li>Random Access<ul>
<li>The larger the block size, the more unrelated data loaded</li>
<li>Spatial locality of access improves the situation</li>
</ul>
</li>
<li>Choosing an appropriate block size is a compromise</li>
</ul>
<h1 id="Virtual-File-System-VFS"><a href="#Virtual-File-System-VFS" class="headerlink" title="Virtual File System(VFS)"></a>Virtual File System(VFS)</h1><ul>
<li>Provides single system call interface for many file systems</li>
<li>Transparent handling of network file systems</li>
<li>File-based interface to arbitrary device drivers</li>
<li>File-based interface to kernel data structures</li>
<li>Provides an indirection layer for system calls<ul>
<li>File operation table set up at file open time</li>
<li>Points to actual handling code for particular type</li>
<li>Further file operations redirected to those functions</li>
</ul>
</li>
</ul>
<h2 id="VFS-Interface"><a href="#VFS-Interface" class="headerlink" title="VFS Interface"></a>VFS Interface</h2><h3 id="Two-major-data-types"><a href="#Two-major-data-types" class="headerlink" title="Two major data types"></a>Two major data types</h3><h4 id="VFS"><a href="#VFS" class="headerlink" title="VFS"></a>VFS</h4><ul>
<li>Represents all file system types</li>
<li>Contains pointers to functions to manipulate each file system as a whole (e.g. mount, unmount)</li>
</ul>
<h4 id="Vnode"><a href="#Vnode" class="headerlink" title="Vnode"></a>Vnode</h4><ul>
<li>Represents a file (inode) in the underlying filesystem</li>
<li>Points to the real inode</li>
<li>Contains pointers to functions to manipulate files/inodes (e.g. open, close, read, write,…)</li>
</ul>
<h2 id="File-Descriptors"><a href="#File-Descriptors" class="headerlink" title="File Descriptors"></a>File Descriptors</h2><ul>
<li>Each open file has a file descriptor</li>
<li>Read/Write/lseek/…. use them to specify which file to operate on.</li>
</ul>
<p>State associated with a file descriptor</p>
<ul>
<li>File pointer<ul>
<li>Determines where in the file the next read or write is performed</li>
</ul>
</li>
<li>Mode<ul>
<li>Was the file opened read-only, etc…. </li>
</ul>
</li>
</ul>
<h1 id="Memory-Management"><a href="#Memory-Management" class="headerlink" title="Memory Management"></a>Memory Management</h1><h2 id="OS-Memory-Management"><a href="#OS-Memory-Management" class="headerlink" title="OS Memory Management"></a>OS Memory Management</h2><ul>
<li><p>Keeps track of what memory is in use and what memory is free </p>
</li>
<li><p>Allocates free memory to process when needed </p>
<ul>
<li>And deallocates it when they don’t </li>
</ul>
</li>
<li><p>Manages the transfer of memory between RAM and disk.</p>
</li>
<li><p>Two broad classes of memory management systems </p>
<ul>
<li>Those that transfer processes to and from external storage during execution. <ul>
<li>Called swapping or paging </li>
</ul>
</li>
<li>Those that don’t <ul>
<li>Simple </li>
<li>Might find this scheme in an embedded device, dumb phone, or smartcard.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Basic-Memory-Management"><a href="#Basic-Memory-Management" class="headerlink" title="Basic Memory Management"></a>Basic Memory Management</h2><p>Monoprogramming without Swapping or Paging</p>
<p><img src="https://i.loli.net/2020/08/11/NfeLorh5vn1XDRt.png" alt=""></p>
<p>Three simple ways of organizing memory</p>
<blockquote>
<h3 id="Monoprogramming"><a href="#Monoprogramming" class="headerlink" title="Monoprogramming"></a>Monoprogramming</h3><p>Okay if </p>
<ul>
<li>Only have one thing to do </li>
<li>Memory available approximately equates to memory required</li>
<li>Otherwise, <ul>
<li>Poor CPU utilisation in the presence of I/O waiting</li>
<li>Poor memory utilisation with a varied job mix</li>
</ul>
</li>
</ul>
</blockquote>
<h2 id="Fixed-partitioning"><a href="#Fixed-partitioning" class="headerlink" title="Fixed partitioning"></a>Fixed partitioning</h2><h3 id="Simple-MM-Fixed-equal-sized-partitions"><a href="#Simple-MM-Fixed-equal-sized-partitions" class="headerlink" title="Simple MM: Fixed, equal-sized partitions"></a>Simple MM: Fixed, equal-sized partitions</h3><ul>
<li>Any unused space in the partition is wasted <ul>
<li>Called internal fragmentation </li>
</ul>
</li>
<li>Processes smaller than main memory, but larger than a partition cannot run</li>
</ul>
<h3 id="Simple-MM-Fixed-variable-sized-partitions"><a href="#Simple-MM-Fixed-variable-sized-partitions" class="headerlink" title="Simple MM: Fixed, variable-sized partitions"></a>Simple MM: Fixed, variable-sized partitions</h3><ul>
<li><p>Divide memory at boot time into a selection of different sized partitions </p>
<ul>
<li>Can base sizes on expected workload </li>
</ul>
</li>
<li><p>Each partition has queue: </p>
<ul>
<li>Place process in queue for smallest partition that it fits in. </li>
<li>Processes wait for when assigned partition is empty to start</li>
</ul>
</li>
<li><p>Issue </p>
<ul>
<li>Some partitions may be idle <ul>
<li>Small jobs available, but only large partition free </li>
<li>Workload could be unpredictable</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Alternative-queue-strategy"><a href="#Alternative-queue-strategy" class="headerlink" title="Alternative queue strategy"></a>Alternative queue strategy</h3><p>Single queue, search for any jobs that fit </p>
<ul>
<li><p>Small jobs in large partition if necessary </p>
</li>
<li><p>Increases internal memory fragmentation</p>
</li>
</ul>
<h3 id="Fixed-Partition-Summary"><a href="#Fixed-Partition-Summary" class="headerlink" title="Fixed Partition Summary"></a>Fixed Partition Summary</h3><ul>
<li>Simple </li>
<li>Easy to implement </li>
<li>Can result in poor memory utilisation <ul>
<li>Due to <strong>internal</strong> fragmentation</li>
</ul>
</li>
<li>Used on IBM System 360 operating system (OS/MFT)<ul>
<li>Announced 6 April, 1964 </li>
</ul>
</li>
<li>Still applicable for simple embedded systems <ul>
<li>Static <strong>workload</strong> <strong>known</strong> in advance</li>
</ul>
</li>
</ul>
<h2 id="Dynamic-Partitioning"><a href="#Dynamic-Partitioning" class="headerlink" title="Dynamic Partitioning"></a>Dynamic Partitioning</h2><ul>
<li><p>Partitions are of variable length </p>
<ul>
<li>Allocated on-demand from ranges of free memory </li>
</ul>
</li>
<li><p>Process is allocated exactly what it needs </p>
<ul>
<li>Assumes a process knows what it needs</li>
</ul>
</li>
<li><p>We end up with unusable holes (<strong>external</strong> fragmentation)</p>
</li>
</ul>
<h3 id="Classic-Approach"><a href="#Classic-Approach" class="headerlink" title="Classic Approach"></a>Classic Approach</h3><p>Represent available memory as a linked list of available “holes” (free memory ranges). </p>
<ul>
<li>Base, size </li>
<li>Kept in order of increasing address <ul>
<li>Simplifies merging of adjacent holes into larger holes. </li>
</ul>
</li>
<li>List nodes be stored in the “holes” themselves</li>
</ul>
<h3 id="Dynamic-Partitioning-Placement-Algorithm"><a href="#Dynamic-Partitioning-Placement-Algorithm" class="headerlink" title="Dynamic Partitioning Placement Algorithm"></a>Dynamic Partitioning Placement Algorithm</h3><h4 id="First-fit-algorithm"><a href="#First-fit-algorithm" class="headerlink" title="First-fit algorithm"></a>First-fit algorithm</h4><ul>
<li>Scan the list for the first entry that fits <ul>
<li>If greater in size, break it into an allocated and free part </li>
<li>Intent: Minimise amount of searching performed </li>
</ul>
</li>
<li>Aims to find a match quickly </li>
<li>Biases allocation to one end of memory </li>
<li>Tends to preserve larger blocks at the end of memory</li>
</ul>
<h4 id="Next-fit"><a href="#Next-fit" class="headerlink" title="Next-fit"></a>Next-fit</h4><ul>
<li>Like first-fit, except it begins its search from the point in list where the last request succeeded instead of at the beginning.<ul>
<li>(Flawed) Intuition: spread allocation more uniformly over entire memory to avoid skipping over small holes at start of memory </li>
<li>Performs <strong>worse than first-fit</strong> as it breaks up the large free space at end of memory.</li>
</ul>
</li>
</ul>
<h4 id="Best-fit-algorithm"><a href="#Best-fit-algorithm" class="headerlink" title="Best-fit algorithm"></a>Best-fit algorithm</h4><ul>
<li>Chooses the block that is closest in size to the request </li>
<li>Performs w<strong>orse than first-fit</strong> <ul>
<li>Has to search complete list </li>
<li>does more work than first-fit </li>
<li>Since smallest block is chosen for a process, the smallest amount of external fragmentation is left </li>
<li>Create lots of unusable holes</li>
</ul>
</li>
</ul>
<h4 id="Worst-fit-algorithm"><a href="#Worst-fit-algorithm" class="headerlink" title="Worst-fit algorithm"></a>Worst-fit algorithm</h4><ul>
<li>Chooses the block that is largest in size (worst-fit) <ul>
<li>(whimsical) idea is to leave a usable fragment left over </li>
</ul>
</li>
<li>Poor performer <ul>
<li>Has to do more work (like best fit) to search complete list </li>
<li>Does not result in significantly less fragmentation</li>
</ul>
</li>
</ul>
<h3 id="Dynamic-Partition-Allocation-Algorithm-Summary"><a href="#Dynamic-Partition-Allocation-Algorithm-Summary" class="headerlink" title="Dynamic Partition Allocation Algorithm Summary"></a>Dynamic Partition Allocation Algorithm Summary</h3><ul>
<li>First-fit generally better than the others and easiest to implement</li>
</ul>
<h2 id="Compaction"><a href="#Compaction" class="headerlink" title="Compaction"></a>Compaction</h2><ul>
<li><p>We can reduce external fragmentation by compaction </p>
<ul>
<li>Shuffle memory contents to place all free memory together in one large block.</li>
<li>Only if we can relocate running programs? <ul>
<li>Pointers?</li>
</ul>
</li>
</ul>
</li>
<li><p>Generally requires hardware support</p>
</li>
</ul>
<h2 id="When-are-memory-addresses-bound"><a href="#When-are-memory-addresses-bound" class="headerlink" title="When are memory addresses bound?"></a>When are memory addresses bound?</h2><ul>
<li>Compile/link time <ul>
<li>Compiler/Linker binds the addresses </li>
<li>Must know “run” location at compile time </li>
<li>Recompile if location changes </li>
</ul>
</li>
<li>Load time <ul>
<li>Compiler generates relocatable code </li>
<li>Loader binds the addresses at load time </li>
</ul>
</li>
<li>Run time <ul>
<li>Logical compile-time addresses translated to physical addresses by special hardware.</li>
</ul>
</li>
</ul>
<h2 id="Hardware-Support-for-Runtime-Binding-and-Protection"><a href="#Hardware-Support-for-Runtime-Binding-and-Protection" class="headerlink" title="Hardware Support for Runtime Binding and Protection"></a>Hardware Support for Runtime Binding and Protection</h2><ul>
<li>For process B to run using logical addresses <ul>
<li>Process B expects to access addresses from zero to some limit of memory size</li>
<li>Need to add an appropriate offset to its logical addresses <ul>
<li>Achieve relocation </li>
<li>Protect memory “lower” than B </li>
</ul>
</li>
<li>Must limit the maximum logical address B can generate <ul>
<li>Protect memory “higher” than B</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="https://i.loli.net/2020/08/12/DKAoVLU2cIPZmpY.png" alt=""></p>
<h2 id="Base-and-Limit-Register"><a href="#Base-and-Limit-Register" class="headerlink" title="Base and Limit Register"></a>Base and Limit Register</h2><ul>
<li>Also called <ul>
<li>Base and bound registers </li>
<li>Relocation and limit registers</li>
</ul>
</li>
<li>Base and limit registers <ul>
<li>Restrict and relocate the currently active process </li>
<li>Base and limit registers must be changed at <ul>
<li>Load time </li>
<li>Relocation (compaction time) </li>
<li>On a context switch </li>
</ul>
</li>
</ul>
</li>
<li><strong>Pro</strong> <ul>
<li>Supports protected multi-processing (-tasking) </li>
</ul>
</li>
<li><strong>Cons</strong> <ul>
<li>Physical memory allocation must still be contiguous </li>
<li>The entire process must be in memory </li>
<li>Do not support partial sharing of address spaces <ul>
<li>No shared code, libraries, or data structures between processes</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Thus far, we have a system suitable for a batch system</p>
<ul>
<li>Limited number of dynamically allocated processes <ul>
<li>Enough to keep CPU utilised </li>
</ul>
</li>
<li>Relocated at runtime </li>
<li>Protected from each other</li>
</ul>
<h2 id="Swapping"><a href="#Swapping" class="headerlink" title="Swapping"></a>Swapping</h2><ul>
<li><p>A process can be <strong>swapped</strong> temporarily out of memory to a backing store, and then brought back into memory for continued execution. </p>
</li>
<li><p>Backing store – fast disk large enough to accommodate copies of all memory images for all users; must provide direct access to these memory images. </p>
</li>
<li><p>Can prioritize – lower-priority process is swapped out so higher-priority process can be loaded and executed. </p>
</li>
<li><p>Major part of swap time is transfer time; total transfer time is directly proportional to the amount of memory swapped. </p>
<ul>
<li>slow</li>
</ul>
</li>
<li><p>we assume a process is smaller than memory</p>
</li>
</ul>
<h2 id="Virtual-Memory-–-Paging-Overview"><a href="#Virtual-Memory-–-Paging-Overview" class="headerlink" title="Virtual Memory – Paging Overview"></a>Virtual Memory – Paging Overview</h2><ul>
<li><p>Partition <strong>physical</strong> memory into small <strong>equal</strong> sized chunks </p>
<ul>
<li>Called frames </li>
</ul>
</li>
<li><p>Divide each process’s virtual (logical) address space into <strong>same</strong> size chunks </p>
<ul>
<li>Called pages </li>
<li>Virtual memory addresses consist of a page number and offset within the page </li>
</ul>
</li>
<li><p>OS maintains a page table </p>
<ul>
<li><p>contains the frame location for each page </p>
</li>
<li><p>Used by hardware to translate each virtual address to physical address </p>
</li>
<li><p>The relation between virtual addresses and physical memory addresses is given by page table </p>
</li>
</ul>
</li>
<li><p>Process’s physical memory does not have to be contiguous</p>
</li>
<li><p>No external fragmentation </p>
</li>
<li><p>Small internal fragmentation (in last page) </p>
</li>
<li><p>Allows sharing by mapping several pages to the same frame </p>
</li>
<li><p>Abstracts physical organisation </p>
<ul>
<li>Programmer only deal with virtual addresses </li>
</ul>
</li>
<li><p>Minimal support for logical organisation </p>
<ul>
<li>Each unit is one or more pages</li>
</ul>
</li>
</ul>
<h1 id="Virtual-Memory"><a href="#Virtual-Memory" class="headerlink" title="Virtual Memory"></a>Virtual Memory</h1><h2 id="Memory-Management-Unit-or-TLB"><a href="#Memory-Management-Unit-or-TLB" class="headerlink" title="Memory Management Unit(or TLB)"></a>Memory Management Unit(or TLB)</h2><p><img src="https://i.loli.net/2020/08/11/MdNZAm7jUfcIxyt.png" alt="The position and function of the MMU"></p>
<h2 id="Page-based-VM"><a href="#Page-based-VM" class="headerlink" title="Page-based VM"></a>Page-based VM</h2><h3 id="Virtual-Memory-1"><a href="#Virtual-Memory-1" class="headerlink" title="Virtual Memory"></a>Virtual Memory</h3><ul>
<li>Divided into equalsized pages</li>
<li>A mapping is a translation between <ul>
<li>A page and a frame</li>
<li>A page and null</li>
</ul>
</li>
<li>Mappings defined at runtime – They can change</li>
<li>Address space can have holes</li>
<li>Process does not have to be contiguous in physical memory</li>
</ul>
<h3 id="Physical-Memory"><a href="#Physical-Memory" class="headerlink" title="Physical Memory"></a>Physical Memory</h3><ul>
<li>Divided into equal-sized frames</li>
</ul>
<h3 id="Typical-Address-Space-Layout"><a href="#Typical-Address-Space-Layout" class="headerlink" title="Typical Address Space Layout"></a>Typical Address Space Layout</h3><ul>
<li>Stack region is at top, and can grow down</li>
<li>Heap has free space to grow up</li>
<li>Text is typically read-only</li>
<li>Kernel is in a reserved, protected, shared region</li>
<li>0-th page typically not used</li>
</ul>
<h3 id="Page-Faults"><a href="#Page-Faults" class="headerlink" title="Page Faults"></a>Page Faults</h3><blockquote>
<p>Referencing an invalid page triggers a page fault – An exception handled by the OS</p>
</blockquote>
<p>Broadly, two standard page fault types</p>
<ul>
<li>Illegal Address (protection error)<ul>
<li>Signal or kill the process</li>
</ul>
</li>
<li>Page not resident<ul>
<li>Get an empty frame</li>
<li>Load page from disk</li>
<li>Update page (translation) table (enter frame #, set valid bit, etc.)</li>
<li>Restart the faulting instruction</li>
</ul>
</li>
</ul>
<h3 id="Shared-Pages"><a href="#Shared-Pages" class="headerlink" title="Shared Pages"></a>Shared Pages</h3><ul>
<li>Private code and data<ul>
<li>Each process has own copy of code and data</li>
<li>Code and data can appear anywhere in the address space</li>
</ul>
</li>
<li>Shared code<ul>
<li>Single copy of code shared between all processes executing it</li>
<li>Code must not be self modifying</li>
<li>Code must appear at same address in all processes</li>
</ul>
</li>
</ul>
<h3 id="Page-Table-Structure"><a href="#Page-Table-Structure" class="headerlink" title="Page Table Structure"></a>Page Table Structure</h3><p>Page table is (logically) an array of frame numbers</p>
<ul>
<li><p>Index by page number</p>
<p>Each page-table entry (PTE) also has other bits</p>
</li>
<li><p>Present/Absent bit</p>
<ul>
<li>Also called valid bit, it indicates a valid mapping for the page</li>
</ul>
</li>
<li><p>Modified bit</p>
<ul>
<li>Also called dirty bit, it indicates the page may have been modified in memory</li>
</ul>
</li>
<li><p>Reference bit</p>
<ul>
<li>Indicates the page has been accessed</li>
</ul>
</li>
<li><p>Protection bits</p>
<ul>
<li>Read permission, Write permission, Execute permission</li>
<li>Or combinations of the above</li>
</ul>
</li>
<li><p>Caching bit</p>
<ul>
<li>Use to indicate processor should bypass the cache when accessing memory<ul>
<li>Example: to access device registers or memory</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Address-Translation"><a href="#Address-Translation" class="headerlink" title="Address Translation"></a>Address Translation</h3><p>Every (virtual) memory address issued by the CPU must be translated to physical memory</p>
<ul>
<li>Every load and every store instruction</li>
<li>Every instruction fetch</li>
</ul>
<p>Need Translation Hardware</p>
<p>In paging system, translation involves replace page number with a frame number</p>
<h3 id="Page-Tables"><a href="#Page-Tables" class="headerlink" title="Page Tables"></a>Page Tables</h3><ul>
<li>Page tables are implemented as data structures in main memory</li>
<li>Most processes do not use the full 4GB address space</li>
<li>We need a compact representation that does not waste space</li>
<li>Three basic schemes<ul>
<li>Use data structures that adapt to sparsity</li>
<li>Use data structures which only represent resident pages</li>
<li>Use VM techniques for page tables (details left to extended OS)</li>
</ul>
</li>
</ul>
<h4 id="Two-level-Page-Table"><a href="#Two-level-Page-Table" class="headerlink" title="Two-level Page Table"></a>Two-level Page Table</h4><p>2nd –level page tables representing unmapped pages are not allocated – Null in the top-level page table</p>
<h4 id="Alternative-Inverted-Page-Table"><a href="#Alternative-Inverted-Page-Table" class="headerlink" title="Alternative: Inverted Page Table"></a>Alternative: Inverted Page Table</h4><blockquote>
<p>“Inverted page table” is an array of page numbers sorted (indexed) by frame number (it’s a frame table).</p>
</blockquote>
<p><strong>Algorithm</strong></p>
<ul>
<li>Compute hash of page number</li>
<li>Extract index from hash table</li>
<li>Use this to index into inverted page table</li>
<li>Match the PID and page number in the IPT entry</li>
<li>If match, use the index value as frame # for translation</li>
<li>If no match, get next candidate IPT entry from chain field</li>
<li>If NULL chain entry $\Rightarrow$ page fault</li>
</ul>
<p><strong>Properties of IPTs</strong></p>
<ul>
<li>IPT grows with size of RAM, NOT virtual address space</li>
<li>Frame table is needed anyway (for page replacement, more later)</li>
<li>Need a separate data structure for non-resident pages</li>
<li>Saves a vast amount of space (especially on 64-bit systems)</li>
<li>Used in some IBM and HP workstations</li>
</ul>
<h4 id="Improving-the-IPT-Hashed-Page-Table"><a href="#Improving-the-IPT-Hashed-Page-Table" class="headerlink" title="Improving the IPT: Hashed Page Table"></a>Improving the IPT: Hashed Page Table</h4><ul>
<li>Retain fast lookup of IPT – A single memory reference in best case</li>
<li>Retain page table sized based on physical memory size (not virtual) <ul>
<li>Enable efficient frame sharing</li>
<li>Support more than one mapping for same frame</li>
</ul>
</li>
</ul>
<p><strong>Sizing the Hashed Page Table</strong></p>
<ul>
<li>HPT sized based on physical memory size</li>
<li>With sharing<ul>
<li>Each frame can have more than one PTE</li>
<li>More sharing increases number of slots used – Increases collision likelihood</li>
</ul>
</li>
<li>However, we can tune HPT size based on:<ul>
<li>Physical memory size</li>
<li>Expected sharing</li>
<li>Hash collision avoidance. </li>
</ul>
</li>
<li>HPT a power of 2 multiple of number of physical memory frame</li>
</ul>
<h2 id="VM-Implementation-Issue"><a href="#VM-Implementation-Issue" class="headerlink" title="VM Implementation Issue"></a>VM Implementation Issue</h2><h3 id="Performance"><a href="#Performance" class="headerlink" title="Performance"></a>Performance</h3><p>Each virtual memory reference can cause two physical memory accesses</p>
<ul>
<li>One to fetch the page table entry</li>
<li>One to fetch/store the data</li>
</ul>
<p>$\Rightarrow$ Intolerable performance impact!!</p>
<p><strong>Solution:</strong></p>
<ul>
<li>High-speed cache for page table entries (PTEs)<ul>
<li>Called a translation look-aside buffer (TLB)</li>
<li>Contains recently used page table entries</li>
<li>Associative, high-speed memory, similar to cache memory</li>
<li>May be under OS control (unlike memory cache)</li>
</ul>
</li>
</ul>
<h2 id="TLB"><a href="#TLB" class="headerlink" title="TLB"></a>TLB</h2><blockquote>
<p>Translation Lookaside Buffer</p>
</blockquote>
<ul>
<li>Given a virtual address, processor examines the TLB</li>
<li>If matching PTE found (TLB hit), the address is translated</li>
<li>Otherwise (TLB miss), the page number is used to index the process’s page table<ul>
<li>If PT contains a valid entry, reload TLB and restart</li>
<li>Otherwise, (page fault) check if page is on disk<ul>
<li>If on disk, swap it in</li>
<li>Otherwise, allocate a new page or raise an exception</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="TLB-properties"><a href="#TLB-properties" class="headerlink" title="TLB properties"></a>TLB properties</h3><ul>
<li><p>Page table is (logically) an array of frame numbers</p>
</li>
<li><p>TLB holds a (recently used) subset of PT entries</p>
<ul>
<li>Each TLB entry must be identified (tagged) with the page # it translates</li>
<li>Access is by associative lookup:<ul>
<li>All TLB entries’ tags are concurrently compared to the page #</li>
<li>TLB is associative (or content-addressable) memory</li>
</ul>
</li>
</ul>
</li>
<li><p>TLB may or may not be under direct OS control</p>
<ul>
<li>Hardware-loaded TLB<ul>
<li>On miss, hardware performs PT lookup and reloads TLB</li>
<li>Example: x86, ARM</li>
</ul>
</li>
<li>Software-loaded TLB<ul>
<li>On miss, hardware generates a TLB miss exception, and exception handler reloads TLB</li>
<li>Example: MIPS, Itanium (optionally)</li>
</ul>
</li>
</ul>
</li>
<li><p>TLB size: typically 64-128 entries</p>
</li>
<li><p>Can have separate TLBs for instruction fetch and data access</p>
</li>
<li><p>TLBs can also be used with inverted page tables (and others) </p>
</li>
</ul>
<h3 id="TLB-and-context-switching"><a href="#TLB-and-context-switching" class="headerlink" title="TLB and context switching"></a>TLB and context switching</h3><ul>
<li>TLB is a shared piece of hardware</li>
<li>Normal page tables are per-process (address space)</li>
<li>TLB entries are process-specific<ul>
<li>On context switch need to flush the TLB (invalidate all entries)<ul>
<li>high context-switching overhead (Intel x86)</li>
</ul>
</li>
<li>or tag entries with address-space ID (ASID)<ul>
<li>called a tagged TLB</li>
<li>used (in some form) on all modern architectures</li>
<li>TLB entry: ASID, page #, frame #, valid and write-protect bits</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="TLB-effect"><a href="#TLB-effect" class="headerlink" title="TLB effect"></a>TLB effect</h3><ul>
<li><p>Without TLB</p>
<ul>
<li><p>Average number of physical memory references per virtual reference </p>
<p>= 2</p>
</li>
</ul>
</li>
<li><p>With TLB (assume 99% hit ratio)</p>
<ul>
<li><p>Average number of physical memory references per virtual reference</p>
<p>= 0.99 * 1+ 0.01 * 2</p>
<p>= 1.01</p>
</li>
</ul>
</li>
</ul>
<h2 id="Demand-Paging-Segmentation"><a href="#Demand-Paging-Segmentation" class="headerlink" title="Demand Paging/Segmentation"></a>Demand Paging/Segmentation</h2><ul>
<li>With VM, only parts of the program image need to be resident in memory for execution</li>
<li>Can transfer presently unused pages/segments to disk</li>
<li>Reload non-resident pages/segment on demand.<ul>
<li>Reload is triggered by a page or segment fault</li>
<li>Faulting process is blocked and another scheduled</li>
<li>When page/segment is resident, faulting process is restarted</li>
<li>May require freeing up memory first<ul>
<li>Replace current resident page/segment</li>
<li>How determine replacement “victim”?</li>
</ul>
</li>
<li>If victim is unmodified (“clean”) can simply discard it<ul>
<li>This is reason for maintaining a “dirty” bit in the PT</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Why-does-demand-paging-segmentation-work"><a href="#Why-does-demand-paging-segmentation-work" class="headerlink" title="Why does demand paging/segmentation work?"></a>Why does demand paging/segmentation work?</h3><ul>
<li>Program executes at full speed only when accessing the resident set.</li>
<li>TLB misses introduce delays of several microseconds</li>
<li>Page/segment faults introduce delays of several milliseconds</li>
</ul>
<p><strong>Answer</strong></p>
<ul>
<li>Less physical memory required per process<ul>
<li>Can fit more processes in memory</li>
<li>Improved chance of finding a runnable one</li>
</ul>
</li>
<li>Principle of locality</li>
</ul>
<h3 id="Principle-of-Locality"><a href="#Principle-of-Locality" class="headerlink" title="Principle of Locality"></a>Principle of Locality</h3><ul>
<li><p>An important observation comes from empirical studies of the properties of programs.</p>
<ul>
<li>Programs tend to reuse data and instructions they have used recently.</li>
<li>90/10 rule – “A program spends 90% of its time in 10% of its code”</li>
</ul>
</li>
<li><p>We can exploit this locality of references</p>
</li>
<li><p>An implication of locality is that we can reasonably predict what instructions and data a program will use in the near future based on its accesses in the recent past</p>
</li>
<li><p><strong>Two different types</strong> of locality have been observed:</p>
<ul>
<li><strong>Temporal locality</strong>: states that recently accessed items are likely to be accessed in the near future</li>
<li><strong>Spatial locality</strong>: says that items whose addresses are near one another tend to be referenced close together in time</li>
</ul>
</li>
</ul>
<h3 id="Working-Set"><a href="#Working-Set" class="headerlink" title="Working Set"></a>Working Set</h3><blockquote>
<p>The pages/segments required by an application in a time window ($\Delta$)is called its memory working set.</p>
</blockquote>
<p>Working set is an approximation of a programs’ locality</p>
<ul>
<li>if $\Delta$ too small will not encompass entire locality</li>
<li>if $\Delta$ too large will encompass several localities</li>
<li>if $\Delta = \infin\Rightarrow$ will encompass entire program.</li>
<li>$\Delta$’s size is an application specific tradeoff</li>
</ul>
<p>System should keep resident at least a process’s working set – Process executes while it remains in its working set</p>
<p>Working set tends to change gradually</p>
<ul>
<li>Get only a few page/segment faults during a time window</li>
<li>Possible (but hard) to make intelligent guesses about which pieces will be needed in the future – May be able to pre-fetch page/segments</li>
</ul>
<h3 id="Thrashing"><a href="#Thrashing" class="headerlink" title="Thrashing"></a>Thrashing</h3><p>CPU utilisation tends to increase with the degree of multiprogramming – number of processes in system</p>
<p>Higher degrees of multiprogramming – less memory available per process</p>
<p>Some process’s working sets may no longer fit in RAM – Implies an increasing page fault rate</p>
<p>Eventually many processes have insufficient memory</p>
<ul>
<li>Can’t always find a runnable process</li>
<li>Decreasing CPU utilisation</li>
<li>System become I/O limited</li>
</ul>
<p>This is called thrashing</p>
<p>$ \sum$working set sizes &gt; total physical memory size</p>
<h4 id="Recovery-From-Thrashing"><a href="#Recovery-From-Thrashing" class="headerlink" title="Recovery From Thrashing"></a>Recovery From Thrashing</h4><p>In the presence of increasing page fault frequency and decreasing CPU utilisation</p>
<ul>
<li>Suspend a few processes to reduce degree of multiprogramming</li>
<li>Resident pages of suspended processes will migrate to backing store</li>
<li>More physical memory becomes available</li>
<li>Resume suspended processes later when memory pressure eases</li>
</ul>
<h2 id="VM-Management-Policies"><a href="#VM-Management-Policies" class="headerlink" title="VM Management Policies"></a>VM Management Policies</h2><p>Operation and performance of VM system is dependent on a number of policies:</p>
<ul>
<li>Page table format (may be dictated by hardware)<ul>
<li>Multi-level</li>
<li>Inverted/Hashed</li>
</ul>
</li>
<li>Page size (may be dictated by hardware)</li>
<li>Fetch Policy</li>
<li>Replacement policy</li>
<li>Resident set size<ul>
<li>Minimum allocation</li>
<li>Local versus global allocation</li>
</ul>
</li>
<li>Page cleaning policy</li>
</ul>
<h3 id="Page-Size"><a href="#Page-Size" class="headerlink" title="Page Size"></a>Page Size</h3><p>Increasing page size</p>
<p><span class="emoji" alias="x" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/274c.png?v8">&#x274c;</span> Increases internal fragmentation –  reduces adaptability to working set size</p>
<p><span class="emoji" alias="white_check_mark" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2705.png?v8">&#x2705;</span> Decreases number of pages – Reduces size of page tables</p>
<p><span class="emoji" alias="white_check_mark" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2705.png?v8">&#x2705;</span> Increases TLB coverage – Reduces number of TLB misses</p>
<p><span class="emoji" alias="x" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/274c.png?v8">&#x274c;</span> Increases page fault latency – Need to read more from disk before restarting process</p>
<p><span class="emoji" alias="white_check_mark" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2705.png?v8">&#x2705;</span> Increases swapping I/O throughput – Small I/O are dominated by seek/rotation delays</p>
<p><em><strong>Optimal page size is a (work-load dependent) trade-off</strong></em></p>
<p>Multiple page sizes provide flexibility to optimise the use of the TLB</p>
<ul>
<li>Large page sizes can be use for code</li>
<li>Small page size for thread stacks</li>
</ul>
<p>Most operating systems support only a single page size</p>
<ul>
<li>Dealing with multiple page sizes is hard!</li>
</ul>
<h3 id="Fetch-Policy"><a href="#Fetch-Policy" class="headerlink" title="Fetch Policy"></a>Fetch Policy</h3><blockquote>
<p>Determines when a page should be brought into memory </p>
</blockquote>
<p>Demand paging only loads pages in response to page faults – Many page faults when a process first starts</p>
<p>Pre-paging brings in more pages than needed at the moment</p>
<p>​    <span class="emoji" alias="white_check_mark" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2705.png?v8">&#x2705;</span> Improves I/O performance by reading in larger chunks</p>
<p>​    <span class="emoji" alias="x" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/274c.png?v8">&#x274c;</span> Wastes I/O bandwidth if pre-fetched pages aren’t used</p>
<p>​    <span class="emoji" alias="x" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/274c.png?v8">&#x274c;</span> Especially bad if we eject pages in working set in order to pre-fetch unused pages.</p>
<p>​    <span class="emoji" alias="x" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/274c.png?v8">&#x274c;</span>  Hard to get right in practice</p>
<h3 id="Replacement-Policy"><a href="#Replacement-Policy" class="headerlink" title="Replacement Policy"></a>Replacement Policy</h3><ul>
<li>Page removed should be the page least likely to be references in the near future</li>
<li>Most policies attempt to predict the future behaviour on the basis of past behaviour</li>
<li>Constraint: locked frames<ul>
<li>Kernel code</li>
<li>Main kernel data structure</li>
<li>I/O buffers</li>
<li>Performance-critical user-pages (e.g. for DBMS)</li>
</ul>
</li>
<li>Frame table has a lock (or pinned) bit</li>
</ul>
<h4 id="Optimal-Replacement-policy"><a href="#Optimal-Replacement-policy" class="headerlink" title="Optimal Replacement policy"></a>Optimal Replacement policy</h4><blockquote>
<p>Toss the page that won’t be used for the longest time</p>
</blockquote>
<p><span class="emoji" alias="x" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/274c.png?v8">&#x274c;</span> Impossible to implement</p>
<p><span class="emoji" alias="x" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/274c.png?v8">&#x274c;</span> Only good as a theoretic reference point:The closer a practical algorithm gets to optimal, the better</p>
<h4 id="FIFO-Replacement-Policy"><a href="#FIFO-Replacement-Policy" class="headerlink" title="FIFO Replacement Policy"></a>FIFO Replacement Policy</h4><blockquote>
<p> First-in, first-out: Toss the oldest page</p>
</blockquote>
<p><span class="emoji" alias="white_check_mark" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2705.png?v8">&#x2705;</span> Easy to implement</p>
<p><span class="emoji" alias="x" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/274c.png?v8">&#x274c;</span> Age of a page is isn’t necessarily related to usage</p>
<h4 id="Least-Recently-Used-LRU"><a href="#Least-Recently-Used-LRU" class="headerlink" title="Least Recently Used (LRU)"></a>Least Recently Used (LRU)</h4><blockquote>
<p>Toss the least recently used page</p>
<p>Assumes that page that has not been referenced for a long time is unlikely to be referenced in the near future</p>
</blockquote>
<p><span class="emoji" alias="white_circle" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/26aa.png?v8">&#x26aa;</span> Will work if locality holds</p>
<p><span class="emoji" alias="white_circle" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/26aa.png?v8">&#x26aa;</span> Implementation requires a time stamp to be kept for each page, updated on every reference</p>
<p><span class="emoji" alias="x" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/274c.png?v8">&#x274c;</span> Impossible to implement efficiently</p>
<p><span class="emoji" alias="white_circle" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/26aa.png?v8">&#x26aa;</span>  Most practical algorithms are approximations of LRU</p>
<h4 id="Clock-Page-Replacement"><a href="#Clock-Page-Replacement" class="headerlink" title="Clock Page Replacement"></a>Clock Page Replacement</h4><blockquote>
<p>Clock policy, also called second chance.</p>
<p>Employs a usage or reference bit in the frame table.</p>
<p>Set to one when page is used</p>
<p>While scanning for a victim, reset all the reference bits</p>
<p>Toss the first page with a zero reference bit</p>
</blockquote>
<p><strong>Issue</strong></p>
<p>How do we know when a page is referenced?</p>
<p>Use the valid bit in the PTE:</p>
<ul>
<li>When a page is mapped (valid bit set), set the reference bit</li>
<li>When resetting the reference bit, invalidate the PTE entry</li>
<li>On page fault<ul>
<li>Turn on valid bit in PTE</li>
<li>Turn on reference bit</li>
</ul>
</li>
<li>We thus simulate a reference bit in software</li>
</ul>
<h4 id="Performance-1"><a href="#Performance-1" class="headerlink" title="Performance"></a>Performance</h4><p>It terms of selecting the most appropriate replacement, they rank as follows:</p>
<ol>
<li>Optimal </li>
<li>LRU </li>
<li>Clock </li>
<li>FIFO</li>
</ol>
<h3 id="Resident-Set-Size"><a href="#Resident-Set-Size" class="headerlink" title="Resident Set Size"></a>Resident Set Size</h3><blockquote>
<p>How many frames should each process have?</p>
</blockquote>
<p><strong>Fixed Allocation</strong></p>
<blockquote>
<p>Gives a process a fixed number of pages within which to execute.</p>
<p>Isolates process memory usage from each other</p>
<p>When a page fault occurs, one of the pages of that process must be replaced.</p>
</blockquote>
<p><span class="emoji" alias="x" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/274c.png?v8">&#x274c;</span> Achieving high utilisation is an issue – Some processes have high fault rate while others don’t use their allocation.</p>
<p><strong>Variable Allocation</strong></p>
<blockquote>
<p>Number of pages allocated to a process varies over the lifetime of the process</p>
</blockquote>
<p><em>Global Scope</em></p>
<p>Operating system keeps global list of free frames</p>
<p>Free frame is added to resident set of process when a page fault occurs</p>
<p>If no free frame, replaces one from any process</p>
<p><span class="emoji" alias="white_check_mark" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2705.png?v8">&#x2705;</span> Easiest to implement</p>
<p><span class="emoji" alias="white_check_mark" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2705.png?v8">&#x2705;</span> Adopted by many operating systems</p>
<p><span class="emoji" alias="white_check_mark" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2705.png?v8">&#x2705;</span>  Automatic balancing across system</p>
<p><span class="emoji" alias="x" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/274c.png?v8">&#x274c;</span> Does not provide guarantees for important activities</p>
<p><em>Local Scope</em></p>
<p>Allocate number of page frames to a new process based on</p>
<ul>
<li>Application type  </li>
<li>Program request</li>
<li>Other criteria (priority)</li>
</ul>
<p>When a page fault occurs, select a page from among the resident set of the process that suffers the page fault</p>
<p>Re-evaluate allocation from time to time! </p>
<h3 id="Cleaning-Policy"><a href="#Cleaning-Policy" class="headerlink" title="Cleaning Policy"></a>Cleaning Policy</h3><p>Observation – Clean pages are much cheaper to replace than dirty pages</p>
<p>Demand cleaning</p>
<ul>
<li>A page is written out only when it has been selected for replacement</li>
<li>High latency between the decision to replace and availability of free frame.</li>
</ul>
<p>Precleaning</p>
<ul>
<li>Pages are written out in batches (in the background, the pagedaemon)</li>
<li>Increases likelihood of replacing clean frames</li>
<li>Overlap I/O with current activity</li>
</ul>
<h1 id="Multiprocessor-Systems"><a href="#Multiprocessor-Systems" class="headerlink" title="Multiprocessor Systems"></a>Multiprocessor Systems</h1><h2 id="Amdahl’s-law"><a href="#Amdahl’s-law" class="headerlink" title="Amdahl’s law"></a>Amdahl’s law</h2><p>Given a proportion P of a program that can be made parallel, and the remaining serial portion (1-P), speedup by using N processors$\frac{1}{(1-P)+\frac{P}{N}}$</p>
<h2 id="Types-of-Multiprocessors-MPs"><a href="#Types-of-Multiprocessors-MPs" class="headerlink" title="Types of Multiprocessors (MPs)"></a>Types of Multiprocessors (MPs)</h2><ul>
<li>UMA MP (Uniform Memory Access) <ul>
<li>Access to all memory occurs at the same speed for all processors.</li>
</ul>
</li>
<li>NUMA MP (Non-uniform memory access)<ul>
<li>Access to some parts of memory is faster for some processors than other parts of memory</li>
</ul>
</li>
</ul>
<h2 id="Bus-Based-UMA"><a href="#Bus-Based-UMA" class="headerlink" title="Bus Based UMA"></a>Bus Based UMA</h2><ul>
<li>Simplest MP is more than one processor on a single bus connect to memory<ul>
<li>Bus bandwidth becomes a bottleneck with more than just a few CPUs</li>
</ul>
</li>
<li>Each processor has a cache to reduce its need for access to memory<ul>
<li>Hope is most accesses are to the local cache</li>
<li>Bus bandwidth still becomes a bottleneck with many CPUs</li>
<li>With only a single shared bus, scalability can be limited by the bus bandwidth of the single bus - Caching only helps so much</li>
<li>Alternative bus architectures do exist. <ul>
<li>They improve bandwidth available</li>
<li>Don’t eliminate constraint that bandwidth is limited</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Multi-core-Processor"><a href="#Multi-core-Processor" class="headerlink" title="Multi-core Processor"></a>Multi-core Processor</h2><p>(Multi-core) share the same Bus interface<br>Multiprocessors can</p>
<ul>
<li>Increase computation power beyond that available from a single CPU</li>
<li>Share resources such as disk and memory </li>
</ul>
<p>However </p>
<ul>
<li>Assumes parallelizable workload to be effective</li>
<li>Assumes not I/O bound </li>
<li>Shared buses (bus bandwidth) limits scalability <ul>
<li>Can be reduced via hardware design</li>
<li>Can be reduced by carefully crafted software behaviour<ul>
<li>Good cache locality together with limited data sharing where possible</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="How-do-we-construct-an-OS-for-a-multiprocessor"><a href="#How-do-we-construct-an-OS-for-a-multiprocessor" class="headerlink" title="How do we construct an OS for a multiprocessor?"></a>How do we construct an OS for a multiprocessor?</h2><h3 id="Each-CPU-has-its-own-OS"><a href="#Each-CPU-has-its-own-OS" class="headerlink" title="Each CPU has its own OS?"></a>Each CPU has its own OS?</h3><ul>
<li>Statically allocate physical memory to each CPU</li>
<li>Each CPU runs its own independent OS</li>
<li>Share peripherals</li>
<li>Each CPU (OS) handles its processes system calls</li>
</ul>
<p>Used in early multiprocessor systems to ‘get them going’</p>
<ul>
<li>Simpler to implement</li>
<li>Avoids CPU-based concurrency issues by not sharing</li>
<li>Scales – no shared serial sections </li>
<li>Modern analogy, virtualisation in the cloud.</li>
</ul>
<p><strong>Issues</strong></p>
<ul>
<li>Each processor has its own scheduling queue<ul>
<li>We can have one processor overloaded, and the rest idle </li>
</ul>
</li>
<li>Each processor has its own memory partition<ul>
<li>We can a one processor thrashing, and the others with free memory<ul>
<li>No way to move free memory from one OS to another</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Symmetric-Multiprocessors-SMP"><a href="#Symmetric-Multiprocessors-SMP" class="headerlink" title="Symmetric Multiprocessors (SMP)"></a>Symmetric Multiprocessors (SMP)</h3><ul>
<li>OS kernel run on all processors<ul>
<li>Load and resource are balance between all processors<ul>
<li>Including kernel execution</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>Issue</strong>: Real concurrency in the kernel</p>
<ul>
<li>Need carefully applied synchronisation primitives to avoid disaster</li>
<li>One alternative: A single mutex that make the entire kernel a large critical section<ul>
<li>Only one CPU can be in the kernel at a time</li>
<li>The “big lock” becomes a bottleneck when in-kernel processing exceeds what can be done on a single CPU</li>
</ul>
</li>
<li>Better alternative: identify largely independent parts of the kernel and make each of them their own critical section<ul>
<li>Allows more parallelism in the kernel</li>
</ul>
</li>
<li><strong>Issue</strong>: Difficult task<ul>
<li>Code is mostly similar to uniprocessor code</li>
<li>Hard part is identifying independent parts that don’t interfere with each other<ul>
<li>Remember all the inter-dependencies between OS subsystems.</li>
</ul>
</li>
<li>Lock contention can limit overall system performance</li>
</ul>
</li>
</ul>
<h2 id="Test-and-Set"><a href="#Test-and-Set" class="headerlink" title="Test-and-Set"></a>Test-and-Set</h2><blockquote>
<p>Hardware guarantees that the instruction executes atomically on a CPU.<br>Atomically: As an indivisible unit.<br>The instruction can not stop half way through</p>
</blockquote>
<h2 id="Test-and-Set-on-SMP"><a href="#Test-and-Set-on-SMP" class="headerlink" title="Test-and-Set on SMP"></a>Test-and-Set on SMP</h2><p>It does not work without some extra hardware support</p>
<p>A solution:</p>
<p>Hardware blocks all other CPUs from accessing the bus during the TSL instruction to prevent memory accesses by any other CPU.</p>
<ul>
<li>TSL has mutually exclusive access to memory for duration of instruction.</li>
</ul>
<p>Test-and Set is a busy-wait synchronisation primitive * Called a <strong>spinlock</strong></p>
<p>Issue:</p>
<ul>
<li>Lock contention leads to spinning on the lock<ul>
<li>Spinning on a lock requires blocking the bus which slows all other CPUs down<ul>
<li>Independent of whether other CPUs need a lock or no</li>
<li>Caching does not help reduce bus contention</li>
</ul>
</li>
</ul>
</li>
<li>Either TSL still blocks the bus</li>
<li>Or TSL requires exclusive access to an entry in the local cache</li>
</ul>
<h3 id="Reducing-Bus-Contention"><a href="#Reducing-Bus-Contention" class="headerlink" title="Reducing Bus Contention"></a>Reducing Bus Contention</h3><ul>
<li>Read before TSL<ul>
<li>Spin reading the lock variable waiting for it to change</li>
<li>When it does, use TSL to acquire the lock</li>
</ul>
</li>
<li>Allows lock to be shared read-only in all caches until its released<ul>
<li>no bus traffic until actual release</li>
</ul>
</li>
<li>No race conditions, as acquisition is still with TSL.</li>
<li>Test and set performs poorly once there is enough CPUs to cause contention for lock<ul>
<li>Expected</li>
</ul>
</li>
<li>Read before Test and Set performs better<ul>
<li>Performance less than expected</li>
<li>Still significant contention on lock when CPUs notice release and all attempt acquisition</li>
</ul>
</li>
<li>Critical section performance degenerates<ul>
<li>Critical section requires bus traffic to modify shared structure</li>
<li>Lock holder competes with CPU that’s waiting as they test and set, so the lock holder is slower</li>
<li>Slower lock holder results in more contention</li>
</ul>
</li>
</ul>
<h2 id="Cache-Consistency"><a href="#Cache-Consistency" class="headerlink" title="Cache Consistency"></a>Cache Consistency</h2><p>Cache consistency is usually handled by the hardware.</p>
<h2 id="Spinning-versus-Blocking-and-Switching"><a href="#Spinning-versus-Blocking-and-Switching" class="headerlink" title="Spinning versus Blocking and Switching"></a>Spinning versus Blocking and Switching</h2><ul>
<li>Spinning (busy-waiting) on a lock makes no sense on a uniprocessor<ul>
<li>The was no other running process to release the lock</li>
<li>Blocking and (eventually) switching to the lock holder is the only sensible option.</li>
</ul>
</li>
<li>On SMP systems, the decision to spin or block is not as clear.<ul>
<li>The lock is held by another running CPU and will be freed without necessarily switching away from the requestor</li>
</ul>
</li>
</ul>
<h2 id="Spinning-versus-Switching"><a href="#Spinning-versus-Switching" class="headerlink" title="Spinning versus Switching"></a>Spinning versus Switching</h2><p><strong>Blocking and switching</strong></p>
<ul>
<li>to another process takes time<ul>
<li>Save context and restore another</li>
<li>Cache contains current process not new process<ul>
<li>Adjusting the cache working set also takes time</li>
</ul>
</li>
<li>TLB is similar to cache</li>
<li>Switching back when the lock is free encounters the same again</li>
</ul>
</li>
</ul>
<p><strong>Spinning</strong> wastes CPU time <strong>directly</strong> </p>
<h3 id="Trade-off"><a href="#Trade-off" class="headerlink" title="Trade off"></a>Trade off</h3><p>If lock is held for less time than the overhead of switching to and back</p>
<p>​     $\Rightarrow$ It’s more efficient to spin<br> $\Rightarrow$  Spinlocks expect critical sections to be short<br>​     $\Rightarrow$  No waiting for I/O within a spinlock<br>​     $\Rightarrow$  No nesting locks within a spinlock </p>
<h2 id="Preemption-and-Spinlocks"><a href="#Preemption-and-Spinlocks" class="headerlink" title="Preemption and Spinlocks"></a>Preemption and Spinlocks</h2><ul>
<li>Critical sections synchronised via spinlocks are expected to be short<ul>
<li>Avoid other CPUs wasting cycles spinning</li>
</ul>
</li>
<li>What happens if the spinlock holder is preempted at end of holder’s timeslice<ul>
<li>Mutual exclusion is still guaranteed</li>
<li>Other CPUs will spin until the holder is scheduled again!!!!!</li>
</ul>
</li>
</ul>
<p>$\Rightarrow$ Spinlock implementations disable interrupts in addition to acquiring locks to avoid lock-holder preemption</p>
<h1 id="Scheduling"><a href="#Scheduling" class="headerlink" title="Scheduling"></a>Scheduling</h1><blockquote>
<p>The scheduler decides who to run next. This process is sheduling</p>
</blockquote>
<h2 id="Application-behaviour"><a href="#Application-behaviour" class="headerlink" title="Application behaviour"></a>Application behaviour</h2><p>Bursts of CPU usage alternate with periods of I/O wait<br><strong>a) CPU-Bound process</strong></p>
<ul>
<li>Spends most of its computing</li>
<li>Time to completion largely determined by received CPU time</li>
</ul>
<p><strong>b) I/O-Bound process</strong></p>
<ul>
<li>Spend most of its time waiting for I/O to complete<ul>
<li>Small bursts of CPU to process I/O and request next I/O </li>
</ul>
</li>
<li>Time to completion largely determined by I/O request time</li>
<li>We need a mix of CPU-bound and I/O-bound processes to keep both CPU and I/O systems busy</li>
<li>Process can go from CPU- to I/O-bound (or vice versa) in different phases of execution</li>
</ul>
<h2 id="Key-Insights"><a href="#Key-Insights" class="headerlink" title="Key Insights"></a>Key Insights</h2><p>Choosing to run an I/O-bound process delays a CPU-bound process by <strong>very little</strong><br>Choosing to run a CPU-bound process prior to an I/O-bound process delays the next I/O request <strong>significantly</strong></p>
<ul>
<li>No overlap of I/O waiting with computation</li>
<li>Results in device (disk) not as busy as possible</li>
<li>Generally, favour I/O-bound processes over CPU-bound processes</li>
<li>Generally, a scheduling decision is required when a process (or thread) can no longer continue, or when an activity results in more than one ready process</li>
</ul>
<h2 id="Preemptive-versus-Non-preemptive-Scheduling"><a href="#Preemptive-versus-Non-preemptive-Scheduling" class="headerlink" title="Preemptive versus Non-preemptive Scheduling"></a>Preemptive versus Non-preemptive Scheduling</h2><p>Non-preemptive</p>
<ul>
<li>Once a thread is in the running state, it continues until it completes, blocks on I/O, or voluntarily yields the CPU</li>
<li>A single process can monopolised the entire system<br>Preemptive Scheduling (responsive system)</li>
<li>Current thread can be interrupted by OS and moved to ready state.</li>
<li>Usually after a timer interrupt and process has exceeded its maximum run time</li>
<li>Can also be as a result of higher priority process that has become ready (after I/O interrupt).</li>
<li>Ensures fairer service as single thread can’t monopolise the system</li>
<li>Requires a timer interrupt</li>
</ul>
<h2 id="Categories-of-Scheduling-Algorithms"><a href="#Categories-of-Scheduling-Algorithms" class="headerlink" title="Categories of Scheduling Algorithms"></a>Categories of Scheduling Algorithms</h2><p>Batch Systems </p>
<ul>
<li>No users directly waiting, can optimise for overall machine performance </li>
</ul>
<p>Interactive Systems </p>
<ul>
<li>Users directly waiting for their results, can optimise for users perceived performance</li>
</ul>
<p>Realtime Systems </p>
<ul>
<li>Jobs have deadlines, must schedule such that all jobs (predictably) meet their deadlines</li>
</ul>
<h2 id="Goals-of-Scheduling-Algorithms"><a href="#Goals-of-Scheduling-Algorithms" class="headerlink" title="Goals of Scheduling Algorithms"></a>Goals of Scheduling Algorithms</h2><p>All Algorithms</p>
<ul>
<li>Fairness<ul>
<li>Give each process a fair share of the CPU</li>
</ul>
</li>
<li>Policy Enforcement <ul>
<li>What ever policy chosen, the scheduler should ensure it is carried out</li>
</ul>
</li>
<li>Balance/Efficiency<ul>
<li>Try to keep all parts of the system busy </li>
</ul>
</li>
<li>Interactive Algorithms</li>
<li>Minimise response time<ul>
<li>Response time is the time difference between issuing a command and getting the result <ul>
<li>E.g selecting a menu, and getting the result of that selection</li>
</ul>
</li>
<li>Response time is important to the user’s perception of the performance of the system.</li>
</ul>
</li>
<li>Provide Proportionality<ul>
<li>Proportionality is the user expectation that short jobs will have a short response time, and long jobs can have a long response time.</li>
<li>Generally, favour short jobs</li>
</ul>
</li>
<li>Real-time Algorithms<ul>
<li>Must meet deadlines<ul>
<li>Each job/task has a deadline. </li>
<li>A missed deadline can result in data loss or catastrophic failure <ul>
<li>Aircraft control system missed deadline to apply brakes</li>
</ul>
</li>
</ul>
</li>
<li>Provide Predictability<ul>
<li>For some apps, an occasional missed deadline is okay – E.g. DVD decoder</li>
<li>Predictable behaviour allows smooth DVD decoding with only rare skips</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Interactive-scheduling"><a href="#Interactive-scheduling" class="headerlink" title="Interactive scheduling"></a>Interactive scheduling</h2><h3 id="Round-Robin-Scheduling"><a href="#Round-Robin-Scheduling" class="headerlink" title="Round Robin Scheduling"></a>Round Robin Scheduling</h3><ul>
<li>Each process is given a timeslice to run in</li>
<li>When the timeslice expires, the next process preempts the current process, and runs for its timeslice, and so on <ul>
<li>The preempted process is placed at the end of the queue </li>
</ul>
</li>
<li>Implemented with<ul>
<li>A ready queue</li>
<li>A regular timer interrupt</li>
</ul>
</li>
</ul>
<p><strong>Pros</strong> – Fair, easy to implement<br><strong>Con</strong> – Assumes everybody is equal</p>
<p>What should the timeslice be?</p>
<p>Too short</p>
<ul>
<li>Waste a lot of time switching between processes</li>
<li>Example: timeslice of 4ms with 1 ms context switch = 20% round robin overhead </li>
</ul>
<p>Too long</p>
<ul>
<li>System is not responsive</li>
<li>Example: timeslice of 100ms – If 10 people hit “enter” key simultaneously, the last guy to run will only see progress after 1 second.</li>
<li>Degenerates into FCFS if timeslice longer than burst length</li>
</ul>
<h2 id="Priorities"><a href="#Priorities" class="headerlink" title="Priorities"></a>Priorities</h2><ul>
<li>Each Process (or thread) is associated with a priority</li>
<li>Provides basic mechanism to influence a scheduler decision:<ul>
<li>Scheduler will always chooses a thread of higher priority over lower priority</li>
</ul>
</li>
<li>Priorities can be defined internally or externally<ul>
<li>Internal: e.g. I/O bound or CPU bound</li>
<li>External: e.g. based on importance to the user</li>
</ul>
</li>
<li>Usually implemented by multiple priority queues, with round robin on each queue</li>
<li>Con<ul>
<li>Low priorities can starve<ul>
<li>Need to adapt priorities periodically<ul>
<li>Based on ageing or execution history</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Traditional-UNIX-Scheduler"><a href="#Traditional-UNIX-Scheduler" class="headerlink" title="Traditional UNIX Scheduler"></a>Traditional UNIX Scheduler</h2><p>Two-level scheduler</p>
<ul>
<li>High-level scheduler schedules processes between memory and disk</li>
<li>Low-level scheduler is CPU scheduler<ul>
<li>Based on a multilevel queue structure with round robin at each level</li>
</ul>
</li>
<li>The highest priority (lower number) is scheduled </li>
<li>Priorities are re-calculated once per second, and re-inserted in appropriate queue</li>
<li>Avoid starvation of low priority threads</li>
<li>Penalise CPU-bound threads</li>
<li>Priority = CPU_usage +nice +base</li>
<li>CPU_usage = number of clock ticks</li>
<li>Nice is a value given to the process by a user to permanently boost or reduce its priority ( Reduce priority of background jobs)</li>
<li>Base is a set of hardwired, negative values used to boost priority of I/O bound system activities</li>
</ul>
<h3 id="Single-Shared-Ready-Queue"><a href="#Single-Shared-Ready-Queue" class="headerlink" title="Single Shared Ready Queue"></a>Single Shared Ready Queue</h3><p>Pros</p>
<ul>
<li>Simple</li>
<li>Automatic load balancing</li>
</ul>
<p>Cons</p>
<ul>
<li>Lock contention on the ready queue can be a major bottleneck<ul>
<li>Due to frequent scheduling or many CPUs or both</li>
</ul>
</li>
<li>Not all CPUs are equal<ul>
<li>The last CPU a process ran on is likely to have more related entries in the cache</li>
</ul>
</li>
</ul>
<h2 id="Affinity-Scheduling"><a href="#Affinity-Scheduling" class="headerlink" title="Affinity Scheduling"></a>Affinity Scheduling</h2><p>Basic Idea – Try hard to run a process on the CPU it ran on last time</p>
<p>One approach: Multiple Queue Multiprocessor Scheduling</p>
<h2 id="Multiple-Queue-SMP-Scheduling"><a href="#Multiple-Queue-SMP-Scheduling" class="headerlink" title="Multiple Queue SMP Scheduling"></a>Multiple Queue SMP Scheduling</h2><ul>
<li>Each CPU has its own ready queue</li>
<li>Coarse-grained algorithm assigns processes to CPUs  <ul>
<li>Defines their affinity, and roughly balances the load </li>
</ul>
</li>
<li>The bottom-level fine-grained scheduler:<ul>
<li>Is the frequently invoked scheduler (e.g. on blocking on I/O, a lock, or exhausting a timeslice)</li>
<li>Runs on each CPU and selects from its own ready queue</li>
<li>Ensures affinity</li>
<li>If nothing is available from the local ready queue, it runs a process from another CPUs ready queue rather than go idle</li>
<li>Termed “Work stealing”</li>
</ul>
</li>
</ul>
<p><span class="emoji" alias="white_check_mark" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2705.png?v8">&#x2705;</span> No lock contention on per-CPU ready queues in the (hopefully) common case<br><span class="emoji" alias="white_check_mark" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2705.png?v8">&#x2705;</span> Load balancing to avoid idle queues<br><span class="emoji" alias="white_check_mark" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2705.png?v8">&#x2705;</span> Automatic affinity to a single CPU for more cache friendly behaviour</p>
<h1 id="I-O-Management"><a href="#I-O-Management" class="headerlink" title="I/O Management"></a>I/O Management</h1><h2 id="I-O-Devices"><a href="#I-O-Devices" class="headerlink" title="I/O Devices"></a>I/O Devices</h2><p>There exists a large variety of I/O devices:</p>
<ul>
<li>Many of them with different properties</li>
<li>They seem to require different interfaces to manipulate and manage them<ul>
<li>We don’t want a new interface for every device</li>
<li>Diverse, but similar interfaces leads to code duplication</li>
</ul>
</li>
<li>Challenge:<ul>
<li>Uniform and efficient approach to I/O </li>
</ul>
</li>
</ul>
<h2 id="Device-Drivers"><a href="#Device-Drivers" class="headerlink" title="Device Drivers"></a>Device Drivers</h2><p>Drivers classified into similar categories</p>
<ul>
<li>Block devices and character (stream of data) device</li>
</ul>
<p>OS defines a standard (internal) interface to the different classes of devices</p>
<ul>
<li>Example: USB Human Input Device (HID) class specifications<ul>
<li>human input devices follow a set of rules making it easier to design a standard interface.</li>
</ul>
</li>
</ul>
<p>Device drivers job</p>
<ul>
<li>translate request through the device-independent standard interface (open, close, read, write) into appropriate sequence of commands (register manipulations) for the particular hardware</li>
<li>Initialise the hardware at boot time, and shut it down cleanly at shutdown</li>
</ul>
<p>After issuing the command to the device, the device either</p>
<ul>
<li>Completes immediately and the driver simply returns to the caller</li>
<li>Or, device must process the request and the driver usually blocks waiting for an I/O complete interrupt.</li>
</ul>
<p>Drivers are thread-safe as they can be called by another process while a process is already blocked in the driver</p>
<ul>
<li>Thead-safe: Synchronised…</li>
</ul>
<h2 id="Device-Independent-I-O-Software"><a href="#Device-Independent-I-O-Software" class="headerlink" title="Device-Independent I/O Software"></a>Device-Independent I/O Software</h2><p>There is commonality between drivers of similar classes</p>
<p>Divide I/O software into device-dependent and device-independent I/O software</p>
<p>Device independent software includes</p>
<ul>
<li>Buffer or Buffer-cache management</li>
<li>TCP/IP stack</li>
<li>Managing access to dedicated devices</li>
<li>Error reporting</li>
</ul>
<h2 id="I-O-Device-Handling"><a href="#I-O-Device-Handling" class="headerlink" title="I/O Device Handling"></a>I/O Device Handling</h2><p> Data rate</p>
<ul>
<li>May be differences of several orders of magnitude between the data transfer rates</li>
</ul>
<h2 id="Driver-Leftrightarrow-Kernel-Interface"><a href="#Driver-Leftrightarrow-Kernel-Interface" class="headerlink" title="Driver $\Leftrightarrow$ Kernel Interface"></a>Driver $\Leftrightarrow$ Kernel Interface</h2><p>Major Issue is uniform interfaces to devices and kernel</p>
<ul>
<li>Uniform device interface for kernel code<ul>
<li>Allows different devices to be used the same way</li>
<li>Allows internal changes to device driver with fear of breaking kernel code</li>
</ul>
</li>
<li>Uniform kernel interface for device code<ul>
<li>Drivers use a defined interface to kernel services (e.g. kmalloc, install IRQ handler, etc.)</li>
<li>Allows kernel to evolve without breaking existing drivers</li>
</ul>
</li>
<li>Together both uniform interfaces avoid a lot of programming implementing new interfaces<ul>
<li>Retains compatibility as drivers and kernels change over time.</li>
</ul>
</li>
</ul>
<h2 id="Interrupts"><a href="#Interrupts" class="headerlink" title="Interrupts"></a>Interrupts</h2><p><img src="https://i.loli.net/2020/08/12/91kJERBLhyXTl8g.png" alt=""></p>
<ul>
<li>Devices connected to an Interrupt Controller via lines on an I/O bus (e.g. PCI)</li>
<li>Interrupt Controller signals interrupt to CPU and is eventually acknowledged.</li>
<li>Exact details are architecture specific.</li>
</ul>
<h1 id="I-O-Interaction"><a href="#I-O-Interaction" class="headerlink" title="I/O Interaction"></a>I/O Interaction</h1><h2 id="Programmed-I-O"><a href="#Programmed-I-O" class="headerlink" title="Programmed I/O"></a>Programmed I/O</h2><ul>
<li>Also called polling, or busy waiting</li>
<li>I/O module (controller) performs the action, not the processor</li>
<li>Sets appropriate bits in the I/O status register</li>
<li>No interrupts occur</li>
<li>Processor checks status until operation is complete<ul>
<li>Wastes CPU cycles</li>
</ul>
</li>
</ul>
<h2 id="Interrupt-Driven-I-O"><a href="#Interrupt-Driven-I-O" class="headerlink" title="Interrupt-Driven I/O"></a>Interrupt-Driven I/O</h2><ul>
<li>Processor is interrupted when I/O module (controller) ready to exchange data</li>
<li>Processor is free to do other work</li>
<li>No needless waiting</li>
<li>Consumes a lot of processor time because every word read or written passes through the processor</li>
</ul>
<h2 id="Direct-Memory-Access-DMA"><a href="#Direct-Memory-Access-DMA" class="headerlink" title="Direct Memory Access (DMA)"></a>Direct Memory Access (DMA)</h2><ul>
<li>Transfers data directly between Memory and Device</li>
<li>CPU not needed for copying</li>
<li>Transfers a block of data directly to or from memory</li>
<li>An interrupt is sent when the task is complete</li>
<li>The processor is only involved at the beginning and end of the transfer</li>
</ul>
<p><a href="https://sm.ms/image/yj5uc4RskLtX7Bl"><img src="https://camo.githubusercontent.com/2eaefc6a0f092437ad16b57402907a70e8c74cfe/68747470733a2f2f692e6c6f6c692e6e65742f323032302f30382f31322f796a3575633452736b4c745837426c2e706e67" alt="img"></a></p>
<h3 id="DMA-Considerations"><a href="#DMA-Considerations" class="headerlink" title="DMA Considerations"></a>DMA Considerations</h3><p>✅ Reduces number of interrupts</p>
<ul>
<li>Less (expensive) context switches or kernel entry-exits </li>
</ul>
<p>❌ Requires contiguous regions (buffers)</p>
<ul>
<li>Copying</li>
<li>Some hardware supports “Scatter-gather”</li>
</ul>
<p>Synchronous/Asynchronous</p>
<p>Shared bus must be arbitrated (hardware)</p>
<p>– CPU cache reduces (but not eliminates) CPU need for bus</p>
<h1 id="I-O-Management-Software"><a href="#I-O-Management-Software" class="headerlink" title="I/O Management Software"></a>I/O Management Software</h1><h2 id="I-O-Software-Layers"><a href="#I-O-Software-Layers" class="headerlink" title="I/O Software Layers"></a>I/O Software Layers</h2><p><a href="https://sm.ms/image/HR3gJUn56Apsr7B"><img src="https://camo.githubusercontent.com/570a1431dfae252b0637499522201e11d013842f/68747470733a2f2f692e6c6f6c692e6e65742f323032302f30382f31322f485233674a556e35364170737237422e706e67" alt="img"></a></p>
<h2 id="Interrupt-Handlers"><a href="#Interrupt-Handlers" class="headerlink" title="Interrupt Handlers"></a>Interrupt Handlers</h2><ul>
<li>Interrupt handlers<ul>
<li>Can execute at (almost) any time<ul>
<li>Raise (complex) concurrency issues in the kernel</li>
<li>Can propagate to userspace (signals, upcalls), causing similar issues</li>
<li>Generally structured so I/O operations block until interrupts notify them of completion <code>kern/dev/lamebus/lhd.c</code></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Interrupt-Handler-Steps"><a href="#Interrupt-Handler-Steps" class="headerlink" title="Interrupt Handler Steps"></a>Interrupt Handler Steps</h2><ul>
<li><strong>Save Registers</strong> not already saved by hardware interrupt mechanism</li>
<li>(Optionally) <strong>set up context</strong> for interrupt service procedure</li>
<li>Typically, handler runs in the context of the currently running process<ul>
<li><strong>No expensive</strong> context switch</li>
</ul>
</li>
<li><strong>Set up stack</strong> for interrupt service procedure<ul>
<li>Handler usually runs on the kernel stack of current process</li>
<li>Or “nests” if already in kernel mode running on kernel stack</li>
</ul>
</li>
<li><strong>Ack/Mask interrupt controller</strong>, re-enable other interrupts<ul>
<li>Implies potential for interrupt nesting.</li>
</ul>
</li>
<li><strong>Run interrupt service procedure</strong><ul>
<li>Acknowledges interrupt at device level</li>
<li>Figures out what caused the interrupt<ul>
<li>Received a network packet, disk read finished, UART transmit queue empty</li>
</ul>
</li>
<li>If needed, it signals blocked device driver</li>
</ul>
</li>
<li>In some cases, will have woken up a higher priority blocked thread<ul>
<li>Choose newly woken thread to schedule next.</li>
<li>Set up MMU context for process to run next</li>
<li>What if we are nested?</li>
</ul>
</li>
<li>Load new/original process’ registers</li>
<li>Re-enable interrupt; Start running the new process</li>
</ul>
<h2 id="Sleeping-in-Interrupts"><a href="#Sleeping-in-Interrupts" class="headerlink" title="Sleeping in Interrupts"></a>Sleeping in Interrupts</h2><ul>
<li>An interrupt generally has no</li>
</ul>
<p>  context</p>
<p>  (runs on current kernel stack)</p>
<ul>
<li>Unfair to sleep on interrupted process (deadlock possible)</li>
<li>Where to get context for long running operation?</li>
<li>What goes into the ready queue?</li>
</ul>
<ul>
<li><p>What to do?</p>
<ul>
<li>Top and Bottom Half</li>
<li>Linux implements with tasklets and workqueues</li>
<li>Generically, in-kernel thread(s) handle long running kernel operations.</li>
</ul>
</li>
</ul>
<h2 id="Top-Half-Bottom-Half"><a href="#Top-Half-Bottom-Half" class="headerlink" title="Top/Half Bottom Half"></a>Top/Half Bottom Half</h2><p><a href="https://sm.ms/image/hq7xtYoU6GXjeyH"><img src="https://camo.githubusercontent.com/0355867ac61976685db709062c07d784418005db/68747470733a2f2f692e6c6f6c692e6e65742f323032302f30382f31322f6871377874596f553647586a6579482e706e67" alt="img"></a></p>
<ul>
<li>Top Half<ul>
<li>Interrupt handler</li>
<li>remains short</li>
</ul>
</li>
<li>Bottom half<ul>
<li>Is preemptable by top half (interrupts)</li>
<li>performs deferred work (e.g. IP stack processing)</li>
<li>Is checked prior to every kernel exit</li>
<li>signals blocked processes/threads to continue</li>
</ul>
</li>
<li>Enables low interrupt latency</li>
<li>Bottom half can’t block</li>
</ul>
<h2 id="Deferring-Work-on-In-kernel-Threads"><a href="#Deferring-Work-on-In-kernel-Threads" class="headerlink" title="Deferring Work on In-kernel Threads"></a>Deferring Work on In-kernel Threads</h2><ul>
<li>Interrupt<ul>
<li>handler defers work onto in-kernel thread</li>
</ul>
</li>
<li>In-kernel thread handles deferred work (DW)<ul>
<li>Scheduled normally</li>
<li>Can block</li>
</ul>
</li>
<li>Both low interrupt latency and blocking operations</li>
</ul>
<p><a href="https://sm.ms/image/HPAw2jUf7Ylnb8t"><img src="https://camo.githubusercontent.com/d83dae3a02b89d1e414c55152619c9a102b811c5/68747470733a2f2f692e6c6f6c692e6e65742f323032302f30382f31322f48504177326a556637596c6e6238742e706e67" alt="img"></a></p>
<h2 id="Buffering"><a href="#Buffering" class="headerlink" title="Buffering"></a>Buffering</h2><h3 id="No-Buffering"><a href="#No-Buffering" class="headerlink" title="No Buffering"></a>No Buffering</h3><ul>
<li>Process must read/write a device a byte/word at a time<ul>
<li>Each individual system call adds significant overhead</li>
<li>Process must what until each I/O is complete<ul>
<li>Blocking/interrupt/waking adds to overhead.</li>
<li>Many short runs of a process is inefficient (poor CPU cache temporal locality)</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="User-level-Buffering"><a href="#User-level-Buffering" class="headerlink" title="User-level Buffering"></a>User-level Buffering</h3><ul>
<li>Process specifies a memory buffer that incoming data is placed in until it fills<ul>
<li>Filling can be done by interrupt service routine</li>
<li>Only a single system call, and block/wakeup per data buffer<ul>
<li><strong>Much more efficient</strong></li>
</ul>
</li>
</ul>
</li>
<li><strong>Issues</strong><ul>
<li>What happens if buffer is paged out to disk<ul>
<li>Could lose data while unavailable buffer is paged in</li>
<li>Could lock buffer in memory (needed for DMA), however many processes doing I/O reduce RAM available for paging. Can cause deadlock as RAM is limited resource</li>
</ul>
</li>
<li>Consider write case<ul>
<li>When is buffer available for re-use?<ul>
<li>Either process must block until potential slow device drains buffer</li>
<li>or deal with asynchronous signals indicating buffer drained</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Single-Buffer"><a href="#Single-Buffer" class="headerlink" title="Single Buffer"></a>Single Buffer</h3><ul>
<li><p>Operating system assigns a buffer in kernel’s memory for an I/O request</p>
</li>
<li><p>In a stream-oriented scenario</p>
<ul>
<li>Used a line at time</li>
<li>User input from a terminal is one line at a time with carriage return signaling the end of the line</li>
<li>Output to the terminal is one line at a time</li>
</ul>
</li>
<li><p>Block-oriented</p>
<ul>
<li>Input transfers made to buffer</li>
<li>Block copied to user space when needed</li>
<li>Another block is written into the buffer<ul>
<li>Read ahead</li>
</ul>
</li>
</ul>
</li>
<li><p>User process can process one block of data while next block is read in</p>
</li>
<li><p>Swapping can occur since input is taking place in system memory, not user memory</p>
</li>
<li><p>Operating system keeps track of assignment of system buffers to user processes</p>
</li>
<li><p>Assume</p>
<ul>
<li>T is transfer time for a block from device</li>
<li>C is computation time to process incoming block</li>
<li>M is time to copy kernel buffer to user buffer</li>
</ul>
</li>
<li><p>Computation and transfer can be done in parallel</p>
</li>
<li><p>Speed up with buffering</p>
<p><a href="https://sm.ms/image/cRk6qtmy3WQ5UYr"><img src="https://camo.githubusercontent.com/0655d295daf917fc49926538f29597a86fd48203/68747470733a2f2f692e6c6f6c692e6e65742f323032302f30382f31322f63526b3671746d79335751355559722e706e67" alt="img"></a></p>
</li>
<li><p>What happens if kernel buffer is full</p>
<ul>
<li>the user buffer is swapped out, or</li>
<li>The application is slow to process previous buffer and more data is received???</li>
<li>=&gt; We start to lose characters or drop network packets</li>
</ul>
</li>
</ul>
<h2 id="Double-Buffer"><a href="#Double-Buffer" class="headerlink" title="Double Buffer"></a>Double Buffer</h2><ul>
<li>Use two system buffers instead of one</li>
<li>A process can transfer data to or from one buffer while the operating system empties or fills the other buffer</li>
</ul>
<h2 id="Double-Buffer-Speed-Up"><a href="#Double-Buffer-Speed-Up" class="headerlink" title="Double Buffer Speed Up"></a>Double Buffer Speed Up</h2><ul>
<li><p>Computation and Memory copy can be done in parallel with transfer</p>
</li>
<li><p>Speed up with double buffering</p>
</li>
<li><p>Usually M is much less than T giving a favourable result</p>
<p><a href="https://sm.ms/image/cRk6qtmy3WQ5UYr"><img src="https://camo.githubusercontent.com/0655d295daf917fc49926538f29597a86fd48203/68747470733a2f2f692e6c6f6c692e6e65742f323032302f30382f31322f63526b3671746d79335751355559722e706e67" alt="img"></a></p>
</li>
<li><p>May be insufficient for really bursty traffic</p>
<ul>
<li>Lots of application writes between long periods of computation</li>
<li>Long periods of application computation while receiving data</li>
<li>Might want to read-ahead more than a single block for disk</li>
</ul>
</li>
</ul>
<h2 id="Circular-Buffer"><a href="#Circular-Buffer" class="headerlink" title="Circular Buffer"></a>Circular Buffer</h2><ul>
<li>More than two buffers are used</li>
<li>Each individual buffer is one unit in a circular buffer</li>
<li>Used when I/O operation must keep up with process</li>
</ul>
<p><em>Notice that buffering, double buffering, and circular buffering are all Bounded-Buffer Producer-Consumer Problems</em></p>
<p><em><strong>Reference:</strong></em><br>UNSW COMP3231 2020 lecture slides</p>
</div><div class="article-tags size-small mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/OS/">OS</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2020/08/11/paperReview/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Operating Systems</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2020/08/09/FoundationofConcurreny/"><span class="level-item">Foundation of Concurrency</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/avatar.png" alt="Tina"></figure><p class="title is-size-4 is-block line-height-inherit">Tina</p><p class="is-size-6 is-block">A student</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>A secret</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">6</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">3</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">9</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/CutePikachu" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/CutePikachu"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/Paper-Review/"><span class="level-start"><span class="level-item">Paper Review</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/notes/"><span class="level-start"><span class="level-item">notes</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E6%95%99%E7%A8%8B/"><span class="level-start"><span class="level-item">教程</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2020/08/"><span class="level-start"><span class="level-item">August 2020</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/06/"><span class="level-start"><span class="level-item">June 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/03/"><span class="level-start"><span class="level-item">March 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Concurrency/"><span class="tag">Concurrency</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Functional-Programming/"><span class="tag">Functional Programming</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Git/"><span class="tag">Git</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Github/"><span class="tag">Github</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Haskell/"><span class="tag">Haskell</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/OS/"><span class="tag">OS</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/concurrency/"><span class="tag">concurrency</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/notes/"><span class="tag">notes</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/spin/"><span class="tag">spin</span><span class="tag is-grey-lightest">1</span></a></div></div></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" id="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="is-flex" href="#Operating-System-Overview"><span class="mr-2">1</span><span>Operating System Overview</span></a><ul class="menu-list"><li><a class="is-flex" href="#Role"><span class="mr-2">1.1</span><span>Role</span></a><ul class="menu-list"><li><a class="is-flex" href="#Role-1"><span class="mr-2">1.1.1</span><span>Role 1</span></a></li><li><a class="is-flex" href="#Role-2"><span class="mr-2">1.1.2</span><span>Role 2</span></a></li></ul></li><li><a class="is-flex" href="#Structural-Implementation-View"><span class="mr-2">1.2</span><span>Structural (Implementation) View</span></a><ul class="menu-list"><li><a class="is-flex" href="#Operating-System-Kernel"><span class="mr-2">1.2.1</span><span>Operating System Kernel</span></a></li><li><a class="is-flex" href="#The-Operating-System-is-Privileged"><span class="mr-2">1.2.2</span><span>The Operating System is Privileged</span></a></li></ul></li><li><a class="is-flex" href="#The-Structure-of-a-Computer-System"><span class="mr-2">1.3</span><span>The Structure of a Computer System</span></a><ul class="menu-list"><li><a class="is-flex" href="#A-Note-on-System-Libraries"><span class="mr-2">1.3.1</span><span>A Note on System Libraries</span></a></li></ul></li><li><a class="is-flex" href="#Privilege-less-OS"><span class="mr-2">1.4</span><span>Privilege-less OS</span></a></li><li><a class="is-flex" href="#Operating-System-Software"><span class="mr-2">1.5</span><span>Operating System Software</span></a><ul class="menu-list"><li><a class="is-flex" href="#Operating-System-Internal-Structure"><span class="mr-2">1.5.1</span><span>Operating System Internal Structure</span></a></li></ul></li></ul></li><li><a class="is-flex" href="#Processes-and-Threads"><span class="mr-2">2</span><span>Processes and Threads</span></a><ul class="menu-list"><li><a class="is-flex" href="#Major-Requirements-of-an-Operating-System"><span class="mr-2">2.1</span><span>Major Requirements of an Operating System</span></a></li><li><a class="is-flex" href="#Processes-and-Threads-1"><span class="mr-2">2.2</span><span>Processes and Threads</span></a></li><li><a class="is-flex" href="#Process"><span class="mr-2">2.3</span><span>Process</span></a><ul class="menu-list"><li><a class="is-flex" href="#The-Process-Model"><span class="mr-2">2.3.1</span><span>The Process Model</span></a></li><li><a class="is-flex" href="#Process-and-thread-models-of-selected-OSes"><span class="mr-2">2.3.2</span><span>Process and thread models of selected OSes</span></a></li><li><a class="is-flex" href="#Process-Creation"><span class="mr-2">2.3.3</span><span>Process Creation</span></a></li><li><a class="is-flex" href="#Process-Termination"><span class="mr-2">2.3.4</span><span>Process Termination</span></a></li><li><a class="is-flex" href="#Implementation-of-Processes"><span class="mr-2">2.3.5</span><span>Implementation of Processes</span></a></li><li><a class="is-flex" href="#Process-Thread-States"><span class="mr-2">2.3.6</span><span>Process/Thread States</span></a></li><li><a class="is-flex" href="#What-about-blocked-processes"><span class="mr-2">2.3.7</span><span>What about blocked processes</span></a></li><li><a class="is-flex" href="#Implementation"><span class="mr-2">2.3.8</span><span>Implementation</span></a></li></ul></li><li><a class="is-flex" href="#Thread"><span class="mr-2">2.4</span><span>Thread</span></a><ul class="menu-list"><li><a class="is-flex" href="#The-Thread-Model"><span class="mr-2">2.4.1</span><span>The Thread Model</span></a></li><li><a class="is-flex" href="#Thread-Usage"><span class="mr-2">2.4.2</span><span>Thread Usage</span></a></li><li><a class="is-flex" href="#Why-Threads"><span class="mr-2">2.4.3</span><span>Why Threads?</span></a></li><li><a class="is-flex" href="#User-level-Threads"><span class="mr-2">2.4.4</span><span>User-level Threads</span></a></li><li><a class="is-flex" href="#Kernel-level-threads"><span class="mr-2">2.4.5</span><span>Kernel-level threads</span></a></li></ul></li><li><a class="is-flex" href="#Context-Switch"><span class="mr-2">2.5</span><span>Context Switch</span></a><ul class="menu-list"><li><a class="is-flex" href="#Context-Switch-Occurrence"><span class="mr-2">2.5.1</span><span>Context Switch Occurrence</span></a></li><li><a class="is-flex" href="#Context-Switch-1"><span class="mr-2">2.5.2</span><span>Context Switch</span></a></li></ul></li></ul></li><li><a class="is-flex" href="#Concurrency-and-Synchronisation"><span class="mr-2">3</span><span>Concurrency and Synchronisation</span></a><ul class="menu-list"><li><a class="is-flex" href="#Critical-Region"><span class="mr-2">3.1</span><span>Critical Region</span></a><ul class="menu-list"><li><a class="is-flex" href="#Critical-regions-solutions"><span class="mr-2">3.1.1</span><span>Critical regions solutions</span></a></li><li><a class="is-flex" href="#The-producer-Consumer-Problem"><span class="mr-2">3.1.2</span><span>The producer-Consumer Problem</span></a></li><li><a class="is-flex" href="#Semaphores"><span class="mr-2">3.1.3</span><span>Semaphores</span></a></li><li><a class="is-flex" href="#Monitors"><span class="mr-2">3.1.4</span><span>Monitors</span></a></li><li><a class="is-flex" href="#The-Readers-and-Writers-Problem"><span class="mr-2">3.1.5</span><span>The Readers and Writers Problem</span></a></li></ul></li></ul></li><li><a class="is-flex" href="#Deadlock"><span class="mr-2">4</span><span>Deadlock</span></a><ul class="menu-list"><li><a class="is-flex" href="#Resources"><span class="mr-2">4.1</span><span>Resources</span></a><ul class="menu-list"><li><a class="is-flex" href="#Resource-Access"><span class="mr-2">4.1.1</span><span>Resource Access</span></a></li></ul></li><li><a class="is-flex" href="#Deadlock-1"><span class="mr-2">4.2</span><span>Deadlock</span></a><ul class="menu-list"><li><a class="is-flex" href="#Starvation"><span class="mr-2">4.2.1</span><span>Starvation</span></a></li></ul></li></ul></li><li><a class="is-flex" href="#System-Call"><span class="mr-2">5</span><span>System Call</span></a><ul class="menu-list"><li><a class="is-flex" href="#System-Calls"><span class="mr-2">5.1</span><span>System Calls</span></a><ul class="menu-list"><li><a class="is-flex" href="#A-stripped-down-shell"><span class="mr-2">5.1.1</span><span>A stripped down shell:</span></a></li></ul></li><li><a class="is-flex" href="#System-Call-Implementation"><span class="mr-2">5.2</span><span>System Call Implementation</span></a><ul class="menu-list"><li><a class="is-flex" href="#A-Simple-Model-of-CPU-Computation"><span class="mr-2">5.2.1</span><span>A Simple Model of CPU Computation</span></a></li><li><a class="is-flex" href="#Privileged-mode-Operation"><span class="mr-2">5.2.2</span><span>Privileged-mode Operation</span></a></li><li><a class="is-flex" href="#Steps-in-Making-a-System-Call"><span class="mr-2">5.2.3</span><span>Steps in Making a System Call</span></a></li></ul></li></ul></li><li><a class="is-flex" href="#File-Management-1"><span class="mr-2">6</span><span>File Management</span></a><ul class="menu-list"><li><a class="is-flex" href="#Overview-of-the-FS-abstraction"><span class="mr-2">6.1</span><span>Overview of the FS abstraction</span></a></li><li><a class="is-flex" href="#File-Names"><span class="mr-2">6.2</span><span>File Names</span></a></li><li><a class="is-flex" href="#File-Structure"><span class="mr-2">6.3</span><span>File Structure</span></a></li><li><a class="is-flex" href="#File-Types"><span class="mr-2">6.4</span><span>File Types</span></a></li><li><a class="is-flex" href="#File-Access-Types-Patterns"><span class="mr-2">6.5</span><span>File Access Types(Patterns)</span></a><ul class="menu-list"><li><a class="is-flex" href="#Typical-File-Operations"><span class="mr-2">6.5.1</span><span>Typical File Operations</span></a></li><li><a class="is-flex" href="#File-Organisation-and-Access"><span class="mr-2">6.5.2</span><span>File Organisation and Access</span></a></li><li><a class="is-flex" href="#Criteria-for-File-Organization"><span class="mr-2">6.5.3</span><span>Criteria for File Organization</span></a></li><li><a class="is-flex" href="#File-Directories"><span class="mr-2">6.5.4</span><span>File Directories</span></a></li><li><a class="is-flex" href="#Hierarchical-Tree-Structured-Directory"><span class="mr-2">6.5.5</span><span>Hierarchical (Tree-Structured) Directory</span></a></li><li><a class="is-flex" href="#Current-Working-Directory"><span class="mr-2">6.5.6</span><span>Current Working Directory</span></a></li><li><a class="is-flex" href="#Relative-and-Absolute-Pathnames"><span class="mr-2">6.5.7</span><span>Relative and Absolute Pathnames</span></a></li><li><a class="is-flex" href="#Typical-Directory-Operations"><span class="mr-2">6.5.8</span><span>Typical Directory Operations</span></a></li><li><a class="is-flex" href="#Nice-properties-of-UNIX-naming"><span class="mr-2">6.5.9</span><span>Nice properties of UNIX naming</span></a></li><li><a class="is-flex" href="#File-Sharing"><span class="mr-2">6.5.10</span><span>File Sharing</span></a></li></ul></li></ul></li><li><a class="is-flex" href="#File-System"><span class="mr-2">7</span><span>File System</span></a><ul class="menu-list"><li><a class="is-flex" href="#File-Allocation-Methods"><span class="mr-2">7.1</span><span>File Allocation Methods</span></a><ul class="menu-list"><li><a class="is-flex" href="#Internal-fragmentation"><span class="mr-2">7.1.1</span><span>Internal fragmentation</span></a></li><li><a class="is-flex" href="#Contiguous-Allocation"><span class="mr-2">7.1.2</span><span>Contiguous Allocation</span></a></li><li><a class="is-flex" href="#Dynamical-Allocation-inode-based-FS-structure"><span class="mr-2">7.1.3</span><span>Dynamical Allocation: inode-based FS structure</span></a></li></ul></li><li><a class="is-flex" href="#FS-reliability"><span class="mr-2">7.2</span><span>FS reliability</span></a></li><li><a class="is-flex" href="#Journaling-file-systems"><span class="mr-2">7.3</span><span>Journaling file systems</span></a><ul class="menu-list"><li><a class="is-flex" href="#Journaling-Block-Device-JBD"><span class="mr-2">7.3.1</span><span>Journaling Block Device (JBD)</span></a></li><li><a class="is-flex" href="#Trade-off-in-FS-block-size"><span class="mr-2">7.3.2</span><span>Trade-off in FS block size</span></a></li></ul></li></ul></li><li><a class="is-flex" href="#Virtual-File-System-VFS"><span class="mr-2">8</span><span>Virtual File System(VFS)</span></a><ul class="menu-list"><li><a class="is-flex" href="#VFS-Interface"><span class="mr-2">8.1</span><span>VFS Interface</span></a><ul class="menu-list"><li><a class="is-flex" href="#Vnode"><span class="mr-2">8.1.1</span><span>Vnode</span></a></li></ul></li><li><a class="is-flex" href="#File-Descriptors"><span class="mr-2">8.2</span><span>File Descriptors</span></a></li></ul></li><li><a class="is-flex" href="#Memory-Management"><span class="mr-2">9</span><span>Memory Management</span></a><ul class="menu-list"><li><a class="is-flex" href="#OS-Memory-Management"><span class="mr-2">9.1</span><span>OS Memory Management</span></a></li><li><a class="is-flex" href="#Basic-Memory-Management"><span class="mr-2">9.2</span><span>Basic Memory Management</span></a><ul class="menu-list"><li><a class="is-flex" href="#Monoprogramming"><span class="mr-2">9.2.1</span><span>Monoprogramming</span></a></li></ul></li><li><a class="is-flex" href="#Fixed-partitioning"><span class="mr-2">9.3</span><span>Fixed partitioning</span></a><ul class="menu-list"><li><a class="is-flex" href="#Simple-MM-Fixed-equal-sized-partitions"><span class="mr-2">9.3.1</span><span>Simple MM: Fixed, equal-sized partitions</span></a></li><li><a class="is-flex" href="#Simple-MM-Fixed-variable-sized-partitions"><span class="mr-2">9.3.2</span><span>Simple MM: Fixed, variable-sized partitions</span></a></li><li><a class="is-flex" href="#Alternative-queue-strategy"><span class="mr-2">9.3.3</span><span>Alternative queue strategy</span></a></li><li><a class="is-flex" href="#Fixed-Partition-Summary"><span class="mr-2">9.3.4</span><span>Fixed Partition Summary</span></a></li></ul></li><li><a class="is-flex" href="#Dynamic-Partitioning"><span class="mr-2">9.4</span><span>Dynamic Partitioning</span></a><ul class="menu-list"><li><a class="is-flex" href="#Classic-Approach"><span class="mr-2">9.4.1</span><span>Classic Approach</span></a></li><li><a class="is-flex" href="#Worst-fit-algorithm"><span class="mr-2">9.4.2</span><span>Worst-fit algorithm</span></a></li><li><a class="is-flex" href="#Dynamic-Partition-Allocation-Algorithm-Summary"><span class="mr-2">9.4.3</span><span>Dynamic Partition Allocation Algorithm Summary</span></a></li></ul></li><li><a class="is-flex" href="#Compaction"><span class="mr-2">9.5</span><span>Compaction</span></a></li><li><a class="is-flex" href="#When-are-memory-addresses-bound"><span class="mr-2">9.6</span><span>When are memory addresses bound?</span></a></li><li><a class="is-flex" href="#Hardware-Support-for-Runtime-Binding-and-Protection"><span class="mr-2">9.7</span><span>Hardware Support for Runtime Binding and Protection</span></a></li><li><a class="is-flex" href="#Base-and-Limit-Register"><span class="mr-2">9.8</span><span>Base and Limit Register</span></a></li><li><a class="is-flex" href="#Swapping"><span class="mr-2">9.9</span><span>Swapping</span></a></li><li><a class="is-flex" href="#Virtual-Memory-–-Paging-Overview"><span class="mr-2">9.10</span><span>Virtual Memory – Paging Overview</span></a></li></ul></li><li><a class="is-flex" href="#Virtual-Memory"><span class="mr-2">10</span><span>Virtual Memory</span></a><ul class="menu-list"><li><a class="is-flex" href="#Memory-Management-Unit-or-TLB"><span class="mr-2">10.1</span><span>Memory Management Unit(or TLB)</span></a></li><li><a class="is-flex" href="#Page-based-VM"><span class="mr-2">10.2</span><span>Page-based VM</span></a><ul class="menu-list"><li><a class="is-flex" href="#Virtual-Memory-1"><span class="mr-2">10.2.1</span><span>Virtual Memory</span></a></li><li><a class="is-flex" href="#Physical-Memory"><span class="mr-2">10.2.2</span><span>Physical Memory</span></a></li><li><a class="is-flex" href="#Typical-Address-Space-Layout"><span class="mr-2">10.2.3</span><span>Typical Address Space Layout</span></a></li><li><a class="is-flex" href="#Page-Faults"><span class="mr-2">10.2.4</span><span>Page Faults</span></a></li><li><a class="is-flex" href="#Shared-Pages"><span class="mr-2">10.2.5</span><span>Shared Pages</span></a></li><li><a class="is-flex" href="#Page-Table-Structure"><span class="mr-2">10.2.6</span><span>Page Table Structure</span></a></li><li><a class="is-flex" href="#Address-Translation"><span class="mr-2">10.2.7</span><span>Address Translation</span></a></li><li><a class="is-flex" href="#Improving-the-IPT-Hashed-Page-Table"><span class="mr-2">10.2.8</span><span>Improving the IPT: Hashed Page Table</span></a></li></ul></li><li><a class="is-flex" href="#VM-Implementation-Issue"><span class="mr-2">10.3</span><span>VM Implementation Issue</span></a><ul class="menu-list"><li><a class="is-flex" href="#Performance"><span class="mr-2">10.3.1</span><span>Performance</span></a></li></ul></li><li><a class="is-flex" href="#TLB"><span class="mr-2">10.4</span><span>TLB</span></a><ul class="menu-list"><li><a class="is-flex" href="#TLB-properties"><span class="mr-2">10.4.1</span><span>TLB properties</span></a></li><li><a class="is-flex" href="#TLB-and-context-switching"><span class="mr-2">10.4.2</span><span>TLB and context switching</span></a></li><li><a class="is-flex" href="#TLB-effect"><span class="mr-2">10.4.3</span><span>TLB effect</span></a></li></ul></li><li><a class="is-flex" href="#Demand-Paging-Segmentation"><span class="mr-2">10.5</span><span>Demand Paging/Segmentation</span></a><ul class="menu-list"><li><a class="is-flex" href="#Why-does-demand-paging-segmentation-work"><span class="mr-2">10.5.1</span><span>Why does demand paging/segmentation work?</span></a></li><li><a class="is-flex" href="#Principle-of-Locality"><span class="mr-2">10.5.2</span><span>Principle of Locality</span></a></li><li><a class="is-flex" href="#Working-Set"><span class="mr-2">10.5.3</span><span>Working Set</span></a></li><li><a class="is-flex" href="#Recovery-From-Thrashing"><span class="mr-2">10.5.4</span><span>Recovery From Thrashing</span></a></li></ul></li><li><a class="is-flex" href="#VM-Management-Policies"><span class="mr-2">10.6</span><span>VM Management Policies</span></a><ul class="menu-list"><li><a class="is-flex" href="#Page-Size"><span class="mr-2">10.6.1</span><span>Page Size</span></a></li><li><a class="is-flex" href="#Fetch-Policy"><span class="mr-2">10.6.2</span><span>Fetch Policy</span></a></li><li><a class="is-flex" href="#Performance-1"><span class="mr-2">10.6.3</span><span>Performance</span></a></li><li><a class="is-flex" href="#Resident-Set-Size"><span class="mr-2">10.6.4</span><span>Resident Set Size</span></a></li><li><a class="is-flex" href="#Cleaning-Policy"><span class="mr-2">10.6.5</span><span>Cleaning Policy</span></a></li></ul></li></ul></li><li><a class="is-flex" href="#Multiprocessor-Systems"><span class="mr-2">11</span><span>Multiprocessor Systems</span></a><ul class="menu-list"><li><a class="is-flex" href="#Amdahl’s-law"><span class="mr-2">11.1</span><span>Amdahl’s law</span></a></li><li><a class="is-flex" href="#Types-of-Multiprocessors-MPs"><span class="mr-2">11.2</span><span>Types of Multiprocessors (MPs)</span></a></li><li><a class="is-flex" href="#Bus-Based-UMA"><span class="mr-2">11.3</span><span>Bus Based UMA</span></a></li><li><a class="is-flex" href="#Multi-core-Processor"><span class="mr-2">11.4</span><span>Multi-core Processor</span></a></li><li><a class="is-flex" href="#How-do-we-construct-an-OS-for-a-multiprocessor"><span class="mr-2">11.5</span><span>How do we construct an OS for a multiprocessor?</span></a><ul class="menu-list"><li><a class="is-flex" href="#Each-CPU-has-its-own-OS"><span class="mr-2">11.5.1</span><span>Each CPU has its own OS?</span></a></li><li><a class="is-flex" href="#Symmetric-Multiprocessors-SMP"><span class="mr-2">11.5.2</span><span>Symmetric Multiprocessors (SMP)</span></a></li></ul></li><li><a class="is-flex" href="#Test-and-Set"><span class="mr-2">11.6</span><span>Test-and-Set</span></a></li><li><a class="is-flex" href="#Test-and-Set-on-SMP"><span class="mr-2">11.7</span><span>Test-and-Set on SMP</span></a><ul class="menu-list"><li><a class="is-flex" href="#Reducing-Bus-Contention"><span class="mr-2">11.7.1</span><span>Reducing Bus Contention</span></a></li></ul></li><li><a class="is-flex" href="#Cache-Consistency"><span class="mr-2">11.8</span><span>Cache Consistency</span></a></li><li><a class="is-flex" href="#Spinning-versus-Blocking-and-Switching"><span class="mr-2">11.9</span><span>Spinning versus Blocking and Switching</span></a></li><li><a class="is-flex" href="#Spinning-versus-Switching"><span class="mr-2">11.10</span><span>Spinning versus Switching</span></a><ul class="menu-list"><li><a class="is-flex" href="#Trade-off"><span class="mr-2">11.10.1</span><span>Trade off</span></a></li></ul></li><li><a class="is-flex" href="#Preemption-and-Spinlocks"><span class="mr-2">11.11</span><span>Preemption and Spinlocks</span></a></li></ul></li><li><a class="is-flex" href="#Scheduling"><span class="mr-2">12</span><span>Scheduling</span></a><ul class="menu-list"><li><a class="is-flex" href="#Application-behaviour"><span class="mr-2">12.1</span><span>Application behaviour</span></a></li><li><a class="is-flex" href="#Key-Insights"><span class="mr-2">12.2</span><span>Key Insights</span></a></li><li><a class="is-flex" href="#Preemptive-versus-Non-preemptive-Scheduling"><span class="mr-2">12.3</span><span>Preemptive versus Non-preemptive Scheduling</span></a></li><li><a class="is-flex" href="#Categories-of-Scheduling-Algorithms"><span class="mr-2">12.4</span><span>Categories of Scheduling Algorithms</span></a></li><li><a class="is-flex" href="#Goals-of-Scheduling-Algorithms"><span class="mr-2">12.5</span><span>Goals of Scheduling Algorithms</span></a></li><li><a class="is-flex" href="#Interactive-scheduling"><span class="mr-2">12.6</span><span>Interactive scheduling</span></a><ul class="menu-list"><li><a class="is-flex" href="#Round-Robin-Scheduling"><span class="mr-2">12.6.1</span><span>Round Robin Scheduling</span></a></li></ul></li><li><a class="is-flex" href="#Priorities"><span class="mr-2">12.7</span><span>Priorities</span></a></li><li><a class="is-flex" href="#Traditional-UNIX-Scheduler"><span class="mr-2">12.8</span><span>Traditional UNIX Scheduler</span></a><ul class="menu-list"><li><a class="is-flex" href="#Single-Shared-Ready-Queue"><span class="mr-2">12.8.1</span><span>Single Shared Ready Queue</span></a></li></ul></li><li><a class="is-flex" href="#Affinity-Scheduling"><span class="mr-2">12.9</span><span>Affinity Scheduling</span></a></li><li><a class="is-flex" href="#Multiple-Queue-SMP-Scheduling"><span class="mr-2">12.10</span><span>Multiple Queue SMP Scheduling</span></a></li></ul></li><li><a class="is-flex" href="#I-O-Management"><span class="mr-2">13</span><span>I/O Management</span></a><ul class="menu-list"><li><a class="is-flex" href="#I-O-Devices"><span class="mr-2">13.1</span><span>I/O Devices</span></a></li><li><a class="is-flex" href="#Device-Drivers"><span class="mr-2">13.2</span><span>Device Drivers</span></a></li><li><a class="is-flex" href="#Device-Independent-I-O-Software"><span class="mr-2">13.3</span><span>Device-Independent I/O Software</span></a></li><li><a class="is-flex" href="#I-O-Device-Handling"><span class="mr-2">13.4</span><span>I/O Device Handling</span></a></li><li><a class="is-flex" href="#Driver-Leftrightarrow-Kernel-Interface"><span class="mr-2">13.5</span><span>Driver $\Leftrightarrow$ Kernel Interface</span></a></li><li><a class="is-flex" href="#Interrupts"><span class="mr-2">13.6</span><span>Interrupts</span></a></li></ul></li><li><a class="is-flex" href="#I-O-Interaction"><span class="mr-2">14</span><span>I/O Interaction</span></a><ul class="menu-list"><li><a class="is-flex" href="#Programmed-I-O"><span class="mr-2">14.1</span><span>Programmed I/O</span></a></li><li><a class="is-flex" href="#Interrupt-Driven-I-O"><span class="mr-2">14.2</span><span>Interrupt-Driven I/O</span></a></li><li><a class="is-flex" href="#Direct-Memory-Access-DMA"><span class="mr-2">14.3</span><span>Direct Memory Access (DMA)</span></a><ul class="menu-list"><li><a class="is-flex" href="#DMA-Considerations"><span class="mr-2">14.3.1</span><span>DMA Considerations</span></a></li></ul></li></ul></li><li><a class="is-flex" href="#I-O-Management-Software"><span class="mr-2">15</span><span>I/O Management Software</span></a><ul class="menu-list"><li><a class="is-flex" href="#I-O-Software-Layers"><span class="mr-2">15.1</span><span>I/O Software Layers</span></a></li><li><a class="is-flex" href="#Interrupt-Handlers"><span class="mr-2">15.2</span><span>Interrupt Handlers</span></a></li><li><a class="is-flex" href="#Interrupt-Handler-Steps"><span class="mr-2">15.3</span><span>Interrupt Handler Steps</span></a></li><li><a class="is-flex" href="#Sleeping-in-Interrupts"><span class="mr-2">15.4</span><span>Sleeping in Interrupts</span></a></li><li><a class="is-flex" href="#Top-Half-Bottom-Half"><span class="mr-2">15.5</span><span>Top/Half Bottom Half</span></a></li><li><a class="is-flex" href="#Deferring-Work-on-In-kernel-Threads"><span class="mr-2">15.6</span><span>Deferring Work on In-kernel Threads</span></a></li><li><a class="is-flex" href="#Buffering"><span class="mr-2">15.7</span><span>Buffering</span></a><ul class="menu-list"><li><a class="is-flex" href="#No-Buffering"><span class="mr-2">15.7.1</span><span>No Buffering</span></a></li><li><a class="is-flex" href="#User-level-Buffering"><span class="mr-2">15.7.2</span><span>User-level Buffering</span></a></li><li><a class="is-flex" href="#Single-Buffer"><span class="mr-2">15.7.3</span><span>Single Buffer</span></a></li></ul></li><li><a class="is-flex" href="#Double-Buffer"><span class="mr-2">15.8</span><span>Double Buffer</span></a></li><li><a class="is-flex" href="#Double-Buffer-Speed-Up"><span class="mr-2">15.9</span><span>Double Buffer Speed Up</span></a></li><li><a class="is-flex" href="#Circular-Buffer"><span class="mr-2">15.10</span><span>Circular Buffer</span></a></li></ul></li></ul></div></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">Recent</h3><article class="media"><div class="media-content size-small"><p><time dateTime="2020-08-11T06:00:00.000Z">2020-08-11</time></p><p class="title is-6"><a class="link-muted" href="/2020/08/11/paperReview/">Operating Systems</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Paper-Review/">Paper Review</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-08-11T06:00:00.000Z">2020-08-11</time></p><p class="title is-6"><a class="link-muted" href="/2020/08/11/OperatingSystems/">Operating Systems</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/notes/">notes</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-08-09T06:00:00.000Z">2020-08-09</time></p><p class="title is-6"><a class="link-muted" href="/2020/08/09/FoundationofConcurreny/">Foundation of Concurrency</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/notes/">notes</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-08-01T06:00:00.000Z">2020-08-01</time></p><p class="title is-6"><a class="link-muted" href="/2020/08/01/Haskell/">Haskell and functional programming</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/notes/">notes</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-06-01T06:00:00.000Z">2020-06-01</time></p><p class="title is-6"><a class="link-muted" href="/2020/06/01/Mac%E8%A3%85spin%E5%92%8Cispin/">Mac装spin和ispin</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/%E6%95%99%E7%A8%8B/">教程</a></p></div></article></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="Tina blog" height="28"></a><p class="size-small"><span>&copy; 2020 Tina</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Email" href="mailto:tinayutong0310@gmail.com"><i class="fa fa-envelope"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'https://CutePikachu.github.io',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to Top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/tororo.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"log":false});</script></body></html>